---
title: Azure Cosmos DB를 사용한 전역 배포 - 기본적인 이해
description: 이 문서에서는 Azure Cosmos DB의 글로벌 배포와 관련된 기술 세부 정보를 제공합니다.
author: SnehaGunda
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 07/02/2020
ms.author: sngun
ms.reviewer: sngun
ms.openlocfilehash: 6d18338bcaa36b499ecfd3787848e6269a738c0e
ms.sourcegitcommit: 03f0db2e8d91219cf88852c1e500ae86552d8249
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/27/2021
ms.locfileid: "123031866"
---
# <a name="global-data-distribution-with-azure-cosmos-db---under-the-hood"></a>Azure Cosmos DB를 사용한 전역 데이터 배포 - 기본적인 이해
[!INCLUDE[appliesto-all-apis](includes/appliesto-all-apis.md)]

Azure Cosmos DB는 Azure의 기본 서비스이므로 공용, 소버린, DoD (국방부) 및 정부 클라우드를 포함한 전 세계 모든 Azure 지역에서 배포됩니다. 데이터 센터 내에서 Azure Cosmos DB를 각각 전용 로컬 스토리지가 있는 대규모 스탬프의 머신에 배포 및 관리합니다. 데이터 센터 내에서 Azure Cosmos DB는 여러 클러스터로 배포되며 각각은 여러 세대의 하드웨어를 잠재적으로 실행할 수 있습니다. 클러스터 내의 컴퓨터는 일반적으로 지역 내의 고가용성을 위해 10-20개의 장애 도메인에 분산됩니다. 다음 이미지에서는 Cosmos DB 글로벌 배포 시스템 토폴로지를 보여 줍니다.

:::image type="content" source="./media/global-dist-under-the-hood/distributed-system-topology.png" alt-text="시스템 토폴로지" border="false":::

**Azure Cosmos DB의 글로벌 배포는 턴키 방식입니다.** 언제든지 몇 번의 클릭만으로 또는 단일 API 호출을 사용하는 프로그래밍 방식으로 Cosmos 데이터베이스와 연결된 지리적 지역을 추가하거나 제거할 수 있습니다. Cosmos 데이터베이스는 결국 Cosmos 컨테이너의 집합으로 구성됩니다. Cosmos DB에서 컨테이너는 배포 및 확장성의 논리 단위 역할을 합니다. 사용자가 만든 컬렉션, 테이블 및 그래프는 (내부적으로) Cosmos 컨테이너입니다. 컨테이너는 완벽히 스키마에 구애받지 않으며 쿼리에 대한 범위를 제공합니다. Cosmos 컨테이너의 데이터는 수집 시 자동으로 인덱싱됩니다. 자동 인덱싱을 사용하면 특히 전역적으로 분산된 설정에서 스키마 또는 인덱스 관리의 해시 없이 데이터를 쿼리할 수 있습니다.  

- 지정된 지역에서 컨테이너 내의 데이터는 사용자가 제공하고 기본 실제 파티션을 통해 투명하게 관리되는 파티션 키를 사용하여 배포됩니다 (*로컬 배포*).  

- 또한 각 실제 파티션은 지리적 영역에 복제됩니다(*글로벌 배포*). 

Cosmos DB를 사용하는 앱이 Cosmos 컨테이너의 처리량을 탄력적으로 확장하거나 더 많은 스토리지를 사용하는 경우 Cosmos DB는 모든 지역에서 파티션 관리 작업 (분할, 복제, 삭제)을 투명하게 처리합니다. Cosmos DB는 확장, 배포 또는 장애와는 독립적으로 컨테이너 내에 있는 데이터의 단일 시스템 이미지를 지속적으로 제공하며, 이는 모든 지역에 걸쳐 전역적으로 배포됩니다.  

다음 이미지와 같이 컨테이너 내의 데이터는 지역 내 및 전 세계 지역 간에 두 차원을 따라 분산됩니다.  

:::image type="content" source="./media/global-dist-under-the-hood/distribution-of-resource-partitions.png" alt-text="실제 파티션" border="false":::

실제 파티션은 *복제본 세트* 라고 하는 복제본 그룹에서 구현됩니다. 각 컴퓨터는 위의 이미지와 같이 고정된 프로세스 집합 내의 다양한 물리적 파티션에 해당하는 수백 개의 복제본을 호스팅합니다. 실제 파티션에 해당하는 복제본은 클러스터 내의 머신과 지역 내의 데이터 센터 간에 동적으로 배치되고 부하가 분산됩니다.  

복제본은 고유하게 Azure Cosmos DB 테넌트에 속합니다. 각 복제본은 Cosmos DB [데이터베이스 엔진](https://www.vldb.org/pvldb/vol8/p1668-shukla.pdf)의 인스턴스를 호스트합니다. 이는 연결된 인덱스뿐만 아니라 리소스도 관리합니다. Cosmos 데이터베이스 엔진은 ARS (atom-record-sequence) 기반 형식 시스템에서 작동합니다. 엔진은 스키마 개념에 독립적이며 레코드의 구조와 인스턴스 값 사이의 경계를 흐리게 합니다. Cosmos DB는 수집 시 모든 항목을 효율적인 방법으로 자동으로 인덱싱하여 사용자가 스키마나 인덱스 관리를 처리하지 않고도 전역적으로 분산된 데이터를 쿼리할 수 있도록 함으로써 완전한 스키마 불가지론성을 실현합니다.

Cosmos 데이터베이스 엔진은 여러 조정 기본 형식, 언어 런타임, 쿼리 프로세서 및 각각 데이터의 트랜잭션 스토리지 및 인덱싱을 담당하는 스토리지 및 인덱싱 하위 시스템 구현을 포함하는 구성 요소로 구성됩니다. 내구성과 고가용성을 제공하기 위해 데이터베이스 엔진은 해당 데이터 및 SSD에 대한 인덱스를 유지하고 복제본 집합 내에서 각각 데이터베이스 엔진 인스턴스 간에 복제합니다. 대규모 테넌트는 더 높은 규모의 처리량 및 스토리지와 동일하며 복제본이 더 크거나 그 수가 더 많거나 둘 다일 수 있습니다. 시스템의 모든 구성 요소는 완전히 비동기식입니다. 즉, 스레드는 전혀 차단되지 않으며, 각 스레드는 불필요한 스레드 스위치를 발생시키지 않고 단시간 동안 작동합니다. 속도 제한 및 역 압력은 승인 제어에서 모든 I/O 경로까지 전체 스택에 걸쳐 연결됩니다. Cosmos 데이터베이스 엔진은 세분화된 동시성을 활용하고, 적은 양의 시스템 리소스 내에서 운영하는 동시에 높은 처리량을 제공하도록 설계되었습니다.

Cosmos DB의 글로벌 배포는 *복제본 세트* 및 *파티션 세트* 라는 두 가지 주요 추상화에 의존합니다. 복제본 세트는 조정을 위한 모듈식 레고 블록이며, 파티션 세트는 지리적으로 분산된 하나 이상의 실제 파티션에 대한 동적 오버레이입니다. 글로벌 배포의 작동 방식을 이해하려면 이러한 두 가지 주요 추상화를 이해해야 합니다. 

## <a name="replica-sets"></a>복제본 집합

실제 파티션은 자체 관리되고 여러 장애 도메인에 걸쳐 동적으로 부하가 분산된 복제본 그룹으로 구체화됩니다(복제본 세트라고 함). 이 세트는 복제된 상태 머신 프로토콜을 전체적으로 구현하여 실제 파티션 내 데이터를 고가용성, 내구성 및 일관성 있게 만듭니다. 복제본 집합 구성원 *N* 은 동적입니다. 장애, 관리 작업 및 실패한 복제본의 재생성/복구 시간에 따라 *NMin* 과 *NMax* 간에 변동을 유지합니다. 멤버 자격 변경에 따라 복제본 프로토콜도 읽기 및 쓰기 쿼럼의 크기를 재구성합니다. 지정된 실제 파티션에 할당된 처리량을 균일하게 분산하기 위해 두 가지 아이디어를 사용합니다. 

- 첫째, 리더의 쓰기 요청 처리 비용이 팔로워에서 업데이트를 적용하는 비용보다 높습니다. 이에 따라, 리더는 팔로워에 비해 더 많은 시스템 리소스를 예산으로 충당합니다. 

- 둘째, 가급적 지정된 일관성 수준에 대한 읽기 쿼럼은 팔로워 복제본으로만 구성됩니다. 필요 없는 경우 읽기를 제공하기 위해 리더에게 연락하지 않습니다. 쿼럼 기반 시스템의 [부하 및 용량](https://www.cs.utexas.edu/~lorenzo/corsi/cs395t/04S/notes/naor98load.pdf) 관계에 대한 연구에서 얻은 여러 아이디어를 Cosmos DB가 지원하는 [5가지 일관성 모델](consistency-levels.md) 에 사용합니다.  

## <a name="partition-sets"></a>파티션 집합

Cosmos 데이터베이스 지역으로 구성된 각각의 실제 파티션 그룹은 구성된 모든 지역에 복제된 동일한 키 세트를 관리하도록 구성됩니다. 이러한 더 높은 조정 기본 형식을 *파티션 세트* 라고 하며, 지정된 키 세트를 관리하는 실제 파티션의 지리적으로 분산된 동적 오버레이입니다. 지정된 실제 파티션 (복제본 세트)의 범위는 클러스터 내로 제한되는 반면, 파티션 세트는 다음 이미지와 같이 클러스터, 데이터 센터 및 지리적 지역을 포괄할 수 있습니다.  

:::image type="content" source="./media/global-dist-under-the-hood/dynamic-overlay-of-resource-partitions.png" alt-text="파티션 세트" border="false":::

파티션 집합을 동일한 키 집합을 소유하는 여러 복제본 집합으로 구성된, 지리적으로 분산된 “슈퍼 복제본 집합”으로 생각할 수 있습니다. 복제본 세트와 마찬가지로, 파티션 세트의 멤버 자격도 동적입니다. 즉, 지정된 파티션 세트에 새 파티션을 추가/제거하기 위한 암시적 실제 파티션 관리 작업에 따라 달라집니다 (예: 컨테이너에서 처리량을 스케일 아웃하는 경우, Cosmos 데이터베이스로 지역을 추가/제거하거나 오류가 발생하는 경우). 파티션 집합의 각 파티션이 자체 복제본 세트 내에서 파티션 집합 구성원을 관리하도록 함으로써 구성원 자격은 완전히 분산되고 가용성이 높습니다. 파티션 세트를 재구성하는 동안 실제 파티션 간 오버레이의 토폴로지도 설정됩니다. 토폴로지는 원본 및 대상 실제 파티션 간의 일관성 수준, 지리적 거리 및 사용 가능한 네트워크 대역폭에 따라 동적으로 선택됩니다.  

서비스를 사용하면 Cosmos 데이터베이스를 단일 쓰기 지역 또는 다중 쓰기 지역으로 구성할 수 있으며, 선택에 따라 파티션 집합은 단 하나의 지역 또는 모든 지역에서 쓰기를 허용하도록 구성됩니다. 시스템은 2단계의 중첩된 일치 프로토콜을 사용합니다. 한 레벨은 쓰기를 허용하는 실제 파티션의 복제본 세트의 복제본에서 작동하고, 다른 한 레벨은 파티션 세트 수준에서 작동하여 파티션 세트 내 모든 커밋된 쓰기에 대해 완벽한 순서를 보장합니다. 이 다층적이고 중첩된 일치는 고가용성을 위한 엄격한 SLA를 구현하고, 동시에 Cosmos DB가 고객에게 제공하는 일관성 모델을 구현하는 데 매우 중요합니다.  

## <a name="conflict-resolution"></a>충돌 해결

업데이트 전파, 충돌 해결 및 인과 관계 추적을 위한 설계는 [유행병 알고리즘](https://www.kth.se/social/upload/51647982f276546170461c46/4-gossip.pdf) 및 [Bayou](https://people.cs.umass.edu/~mcorner/courses/691M/papers/terry.pdf) 시스템에 대한 이전 작업에서 영감을 받았습니다. 아이디어의 핵심은 살아남아 Cosmos DB의 시스템 설계를 전달하는 데 편리한 참조 프레임을 제공하는 한편, Cosmos DB 시스템에 적용되면서 상당한 변화를 겪기도 했습니다. 이것이 필요했던 이유는 이전 시스템이 리소스 거버넌스를 사용하거나, Cosmos DB가 운영해야 하는 규모이거나, 역량 (예: 제한된 부실 일관성)과 엄격하고 포괄적인 SLA를 제공하도록 설계되지 않았기 때문입니다.  

파티션 세트는 여러 지역에 분산되어 있으며 Cosmos DB (다중 지역 작성) 복제 프로토콜에 따라 지정된 파티션 세트로 구성된 실제 파티션 간에 데이터를 복제합니다. 파티션 세트의 각 실제 파티션은 쓰기를 허용하며 일반적으로 해당 지역에 있는 클라이언트에 읽기를 제공합니다. 지역 내의 실제 파티션에서 수락된 쓰기는 지속력 있게 커밋되며 클라이언트에서 승인되기 전에 해당 실제 파티션 내에서 높은 가용성을 제공합니다. 이러한 쓰기는 임시 쓰기이며, 엔트로피 방지 채널을 사용하여 파티션 세트 내의 다른 실제 파티션으로 전파됩니다. 클라이언트는 요청 헤더를 전달하여 임시 쓰기나 커밋된 쓰기를 요청할 수 있습니다. 엔트로피 방지 전파(전파 빈도 포함)는 파티션 세트의 토폴로지, 실제 파티션의 지역적 근접성 및 구성된 일관성 수준에 따라 동적입니다. 파티션 집합 내에서 Cosmos DB는 동적으로 선택된 중재자 파티션과 함께 기본 커밋 체계를 따릅니다. 중재자 선택은 동적이며 오버레이의 토폴로지에 따라 파티션 집합을 재구성하는 데 필수적인 부분입니다. 커밋된 쓰기(다중 행/일괄 처리 업데이트 포함)는 순서가 보장됩니다. 

인과 관계 추적 및 버전 벡터를 위한 인코딩된 벡터 클록(복제본 집합과 파티션 집합 각각에서 각 일치 수준에 해당하는 지역 ID 및 논리적 클록 포함)을 사용하여 업데이트 충돌을 탐지하고 해결합니다. 토폴로지 및 피어 선택 알고리즘은 버전 벡터의 고정적이며 최소한의 스토리지와 최소한의 네트워크 오버헤드를 보장하도록 설계되었습니다. 알고리즘은 엄격한 수렴 속성을 보장합니다.  

여러 쓰기 지역으로 구성된 Cosmos 데이터베이스의 경우, 시스템은 다음을 포함하여 개발자가 선택할 수 있는 유연하며 다양한 자동 충돌 해결 정책을 제공합니다. 

- **LWW (마지막 쓰기 우선)** : 기본적으로 시스템에 정의된 타임스탬프 속성을 사용합니다 (시간 동기화 클록 프로토콜 기반). 또한 Cosmos DB를 사용하면 충돌 해결에 사용할 다른 사용자 지정 숫자 속성을 지정할 수 있습니다.  
- **애플리케이션 정의 사용자 지정 충돌 해결 정책** (병합 절차를 통해 표시됨): 충돌에 대한 애플리케이션 정의 의미 조정을 위해 설계되었습니다. 이러한 프로시저는 서버 쪽의 데이터베이스 트랜잭션에서 쓰기-쓰기 충돌이 검색될 때 호출됩니다. 시스템은 약정 프로토콜의 일부로 병합 프로시저 실행을 정확히 한 번만 보장합니다. 사용할 수 있는 [샘플이 몇 개](how-to-manage-conflicts.md) 있습니다.  

## <a name="consistency-models"></a>일관성 모델

단일 또는 여러 쓰기 지역으로 Cosmos 데이터베이스를 구성한다면, 잘 정의된 5가지 일관성 모델 중에서 선택할 수 있습니다. 다중 쓰기 지역을 사용하도록 설정하기 위해 새로 추가된 지원에서는 다음과 같이 일관성 수준에서 몇 가지 주목할 만한 측면이 있습니다.  

이전과 같이, 제한된 부실 지속성은 모든 읽기가 어떠한 지역의 최신 쓰기로부터 *K개* 접두사 또는 *T초* 내에 완료된다고 보장합니다. 또한, 제한된 부실 지속성은 단조 및 일관된 접두사 보증을 제공합니다. 엔트로피 방지 프로토콜은 속도 제한 방식으로 작동하며, 접두사가 누적되지 않고 쓰기에서 역 압력을 적용할 필요가 없음을 보장합니다. 세션 일관성은 전 세계에서 모노닉 읽기, 모노닉 쓰기, 사용자 고유의 쓰기 읽기, 읽기 후 쓰기 및 일관된 접두사 보장을 보장합니다. 강력한 일관성으로 구성된 데이터베이스의 경우 다중 작성 지역 (짧은 쓰기 대기 시간, 높은 쓰기 가용성)의 이점은 지역 간 동기 복제로 인해 적용되지 않습니다.

Cosmos DB의 5가지 일관성 모델의 의미 체계는 [여기](consistency-levels.md)에 설명되어 있으며, 고수준 TLA+ 사양을 사용한 수학적인 설명은 [여기](https://github.com/Azure/azure-cosmos-tla)에서 확인할 수 있습니다.

## <a name="next-steps"></a>다음 단계

이제 다음 문서를 사용하여 글로벌 배포를 구성하는 방법을 알아봅니다.

* [데이터베이스 계정에서 Azure 지역 추가/제거](how-to-manage-database-account.md#addremove-regions-from-your-database-account)
* [사용자 지정 충돌 해결 정책을 만드는 방법](how-to-manage-conflicts.md#create-a-custom-conflict-resolution-policy)
* Azure Cosmos DB로 마이그레이션하기 위한 용량 계획을 수행하려고 하시나요? 용량 계획을 위해 기존 데이터베이스 클러스터에 대한 정보를 사용할 수 있습니다.
    * 기존 데이터베이스 클러스터의 vCore 및 서버 수만 알고 있는 경우 [vCore 또는 vCPU를 사용하여 요청 단위 예측](convert-vcore-to-request-unit.md)에 대해 읽어보세요. 
    * 현재 데이터베이스 워크로드에 대한 일반적인 요청 비율을 알고 있는 경우 [Azure Cosmos DB 용량 계획 도구를 사용하여 요청 단위 예측](estimate-ru-with-capacity-planner.md)에 대해 읽어보세요.
