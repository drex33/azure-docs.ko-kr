---
title: Custom Speech용 데이터 준비 - Speech Service
titleSuffix: Azure Cognitive Services
description: Microsoft 음성 인식의 정확도를 테스트하거나 사용자 지정 모델을 학습하는 경우 오디오 및 텍스트 데이터가 필요합니다. 이 페이지에서는 데이터 형식, 사용 방법 및 관리 방법에 대해 다룹니다.
services: cognitive-services
author: PatrickFarley
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 02/12/2021
ms.author: pafarley
ms.openlocfilehash: 79846dcb5acb50549231d247530512564ae1beea
ms.sourcegitcommit: f2d0e1e91a6c345858d3c21b387b15e3b1fa8b4c
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 09/07/2021
ms.locfileid: "123542527"
---
# <a name="prepare-data-for-custom-speech"></a>Custom Speech에 대한 데이터 준비

Microsoft 음성 인식의 정확도를 테스트하거나 사용자 지정 모델을 학습하는 경우 오디오 및 텍스트 데이터가 필요합니다. 이 페이지에서는 사용자 지정 음성 모델에 필요한 데이터 형식을 다룹니다.

## <a name="data-diversity"></a>데이터 다양성

사용자 지정 모델을 테스트하고 학습하는 데 사용되는 텍스트와 오디오는 모델이 인식해야 하는 다양한 발화자 및 시나리오 세트의 샘플을 포함해야 합니다.
사용자 지정 모델 테스트 및 학습을 위해 데이터를 수집할 때 다음 요소를 고려합니다.

* 텍스트 및 음성 오디오 데이터는 사용자가 모델과 상호 작용할 때 사용자가 사용하게 될 다양한 종류의 발화문을 포함해야 합니다. 예를 들어 온도 조절을 위한 모델의 경우 사용자가 온도 조절 요청을 위해 사용하게 될 문을 학습시켜야 합니다.
* 데이터에는 모델에서 인식해야 하는 모든 발화의 차이를 포함해야 합니다. 억양, 방언, 언어 혼합, 연령, 성별, 음성 피치, 스트레스 수준 및 녹음 일정 등 많은 요인으로 인해 음성이 달라질 수 있습니다.
* 모델이 사용될 여러 환경(실내, 실외, 도로 노이즈)의 샘플을 포함해야 합니다.
* 프로덕션 시스템에서 사용하게 될 하드웨어 디바이스를 사용하여 오디오를 수집해야 합니다. 모델에서 다양한 품질의 레코딩 디바이스에서 기록된 음성을 식별해야 하는 경우 모델 학습을 위해 제공하는 오디오 데이터는 이러한 다양한 시나리오를 나타내야 합니다.
* 나중에 더 많은 데이터를 모델에 추가할 수 있지만, 데이터 세트를 다양하게 유지하고 프로젝트에 필요한 것을 나타낼 수 있도록 유지하는 데 신경 써야 합니다.
* 사용자 지정 모델 인식에 포함되지 *않은* 데이터를 포함하면 전체적으로 인식 품질이 손상될 수 있으므로 모델에 기록할 필요가 없는 데이터는 포함하지 않습니다.

시나리오의 하위 집합에 대해 학습된 모델은 해당 시나리오에서만 제대로 수행할 수 있습니다. 사용자 지정 모델이 인식해야 하는 시나리오의 전체 범위를 나타내는 데이터를 신중하게 선택합니다.

> [!TIP]
> 모델이 마주하게 될 언어 및 음향에 맞는 작은 샘플 데이터 세트로 시작합니다.
> 예를 들어 프로덕션 시나리오에서 모델이 마주하게 될 동일한 하드웨어와 동일한 음향 환경에서 작지만 대표적인 오디오 샘플을 기록합니다.
> 학습용으로 훨씬 더 큰 데이터 세트를 수집하는 데 투자하기 전에 대표 데이터의 작은 데이터 세트에 문제가 생길 수 있습니다.
>
> 빠르게 시작하려면 샘플 데이터를 사용하는 것이 좋습니다. <a href="https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/customspeech" target="_target">샘플 Custom Speech 데이터</a>는 이 GitHub 리포지토리를 참조하세요.

## <a name="data-types"></a>데이터 형식

다음 표에서는 허용되는 데이터 형식, 각 데이터 형식을 사용해야 하는 경우 및 권장 수량을 확인할 수 있습니다. 모델을 만드는 데 모든 데이터 형식이 필요하지는 않습니다. 데이터 요구 사항은 테스트를 만드는지 모델을 학습시키는지에 따라 다릅니다.

| 데이터 형식 | 테스트용으로 사용 | 권장 수량 | 학습용으로 사용 | 권장 수량 |
|-----------|-----------------|----------|-------------------|----------|
| [오디오](#audio-data-for-testing) | 예<br>시각적 검사에 사용 | 5개 이상의 오디오 파일 | 예 | 해당 없음 |
| [오디오 + 휴먼 레이블 대화 기록](#audio--human-labeled-transcript-data-for-trainingtesting) | 예<br>정확도 평가에 사용 | 0.5-5시간 분량의 오디오 | 예 | 1-20시간 분량의 오디오 |
| [일반 텍스트](#plain-text-data-for-training) | 예 | 해당 사항 없음 | 예 | 1-200MB의 관련 텍스트 |
| [발음](#pronunciation-data-for-training) | 예 | 해당 사항 없음 | 예 | 1KB - 1MB의 발음 텍스트 |

파일은 형식에 따라 데이터 세트로 그룹화하고 .zip 파일로 업로드해야 합니다. 각 데이터 세트는 단일 데이터 형식만 포함할 수 있습니다.

> [!TIP]
> 새 모델을 학습하는 경우 일반 텍스트로 시작합니다. 이 데이터만으로도 특수한 용어와 구문을 인식하는 수준이 향상될 것입니다. 텍스트를 사용한 학습(몇 분)은 오디오를 사용한 학습(며칠)보다 훨씬 빠릅니다.

> [!NOTE]
> 모든 기본 모델이 오디오를 통한 학습을 지원하지는 않습니다. 기본 모델이 이를 지원하지 않는 경우 Speech Service는 대본의 텍스트만 사용하고 오디오는 무시합니다. [언어 지원](language-support.md#speech-to-text)을 참조하여 오디오 데이터를 통한 학습을 지원하는 기본 모델의 목록을 확인하세요. 기본 모델이 오디오 데이터를 통한 학습을 지원하는 경우라도 해당 서비스는 오디오의 일부만 사용할 수 있습니다. 하지만 대본은 모두 사용합니다.
>
> 학습에 사용되는 기본 모델을 변경하고 학습 데이터 세트에 오디오가 있는 경우 선택한 새 기본 모델이 [오디오 데이터를 통한 학습을 지원](language-support.md#speech-to-text)하는지 *항상* 확인합니다. 이전에 사용된 기본 모델에서 오디오 데이터를 통한 학습을 지원하지 않고 학습 데이터 세트에 오디오가 포함된 경우 새 기본 모델의 학습 시간이 몇 시간에서 며칠 이상으로 **크게** 증가할 수 있습니다. Speech Service 구독이 학습 [전용 하드웨어가 있는 지역](custom-speech-overview.md#set-up-your-azure-account)에 있지 **않은** 경우에 특히 그렇습니다.
>
> 위의 단락에 설명된 문제가 발생한 경우 데이터 세트의 오디오 양을 줄이거나 완전히 제거하여 텍스트만 남겨두면 학습 시간을 빠르게 줄일 수 있습니다. 두 번째 옵션은 Speech Service 구독이 학습 [전용 하드웨어가 있는 지역](custom-speech-overview.md#set-up-your-azure-account)에 있지 **않은** 경우에 매우 권장됩니다.
>
> 학습 전용 하드웨어가 있는 지역에서 Speech Service는 학습을 위해 최대 20시간의 오디오를 사용합니다. 다른 지역에서는 최대 8시간의 오디오만 사용합니다.

## <a name="upload-data"></a>데이터 업로드

데이터를 업로드하려면 <a href="https://speech.microsoft.com/customspeech" target="_blank">Custom Speech 포털</a>로 이동합니다. 프로젝트를 만든 후 **음성 데이터 세트** 탭으로 이동하고 **데이터 업로드** 를 클릭하여 마법사를 시작하고 첫 번째 데이터 세트를 만듭니다. 데이터 세트에 대한 음성 데이터 형식을 선택하고 데이터를 업로드합니다.

먼저 **학습** 또는 **테스트** 중 어디에 데이터 세트를 사용할지 지정해야 합니다. **학습** 또는 **테스트** 에 업로드 및 사용할 수 있는 여러 유형의 데이터가 있습니다. 업로드하는 각 데이터 세트는 업로드하기 전에 올바른 형식으로 지정해야 하며 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 다음 섹션에서는 요구 사항에 대해 살펴봅니다.

데이터 세트를 업로드한 후에는 몇 가지 옵션을 사용할 수 있습니다.

* **사용자 지정 모델 학습** 탭으로 이동하여 사용자 지정 모델을 학습할 수 있습니다.
* **테스트 모델** 탭으로 이동하여 오디오 전용 데이터로 품질을 시각적으로 검사하거나 오디오 + 휴먼 레이블 대화 기록 데이터를 사용하여 정확도를 평가할 수 있습니다.


## <a name="audio--human-labeled-transcript-data-for-trainingtesting"></a>학습/테스트용 오디오 + 휴먼 레이블 대화 기록 데이터

오디오 + 휴먼 레이블 대화 기록 데이터는 학습 및 테스트 목적으로 모두 사용할 수 있습니다. 약간의 악센트, 말하기 스타일, 배경 소음과 같은 음향적인 측면을 개선하거나 오디오 파일을 처리할 때 Microsoft의 음성 텍스트 전환 정확성을 측정하려면 비교할 수 있도록 휴먼 레이블 대화 기록(단어별)을 제공해야 합니다. 휴먼 레이블 대화 기록은 시간이 많이 소요되는 일이지만 정확성을 평가하고 사용 사례에 맞게 모델을 학습하는 데 필요합니다. 인식 기능의 향상은 제공된 데이터에 따라 달라집니다. 따라서 고품질의 대화 기록만 업로드하는 것이 중요합니다.

오디오 파일에는 시작과 끝에 침묵이 있을 수 있습니다. 가능하면 각 샘플 파일에서 음성 앞과 뒤에 0.5초 정도의 침묵을 포함합니다. 녹음 볼륨이 낮거나 배경 노이즈가 심한 오디오는 유용하지 않지만 사용자 지정 모델을 손상시키지는 않습니다. 오디오 샘플을 수집하기 전에 항상 마이크 및 신호 처리 하드웨어를 업그레이드하는 것이 좋습니다.

| 속성                 | 값                               |
|--------------------------|-------------------------------------|
| 파일 형식              | RIFF(WAV)                          |
| 샘플 속도              | 8,000Hz 또는 16,000Hz               |
| 채널                 | 1(mono)                            |
| 오디오 당 최대 길이 | 2시간(테스트)/60초(학습) |
| 샘플 형식            | PCM, 16비트                         |
| 보관 형식           | .zip                                |
| 최대 zip 크기         | 2GB                                |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!NOTE]
> 학습 및 테스트 데이터를 업로드할 때 .zip 파일 크기는 2GB를 초과할 수 없습니다. *단일* 데이터 세트에서만 테스트할 수 있으며 적절한 파일 크기로 유지해야 합니다. 또한 각 학습 파일은 60초를 초과할 수 없습니다. 그렇지 않으면 오류가 발생합니다.

단어 삭제 또는 대체와 같은 문제를 해결하려면 인식 기능을 개선하기 위해 상당한 양의 데이터가 필요합니다. 일반적으로 1~20시간의 오디오에 대한 단어별 대화 기록을 제공하는 것이 좋습니다. 그러나 30분 정도의 대화 기록을 사용하더라도 인식 결과를 개선하는 데 도움이 될 수 있습니다. 모든 WAV 파일에 대한 전사는 단일 일반 텍스트 파일에 포함되어야 합니다. 전사 파일의 각 줄은 오디오 파일 중 하나의 이름을 포함하고 그 뒤에 해당 전사가 와야 합니다. 파일 이름과 전사는 탭(\t)으로 구분 해야 합니다.

예를 들면 다음과 같습니다.

<!-- The following example contains tabs. Don't accidentally convert these into spaces. -->

```input
speech01.wav    speech recognition is awesome
speech02.wav    the quick brown fox jumped all over the place
speech03.wav    the lazy dog was not amused
```

> [!IMPORTANT]
> 전사는 UTF-8 BOM으로 인코딩해야 합니다.

전사는 시스템에서 처리할 수 있도록 텍스트로 정규화됩니다. 그러나 데이터를 Speech Studio에 업로드하기 전에 수행해야 하는 몇 가지 중요한 정규화 작업이 있습니다. 대화 기록을 준비할 때 사용해야 하는 적절한 언어는 [휴먼 레이블 대화 기록을 만드는 방법](how-to-custom-speech-human-labeled-transcriptions.md)을 참조하세요.

오디오 파일 및 해당 대화 기록을 수집한 후 <a href="https://speech.microsoft.com/customspeech" target="_blank">Speech Studio</a>에 업로드하기 전에 단일 .zip 파일로 패키징합니다. 다음은 세 개의 오디오 파일과 휴먼 레이블 대화 기록 파일이 있는 예제 데이터 세트입니다.

> [!div class="mx-imgBorder"]
> ![Speech Portal에서 오디오 선택](./media/custom-speech/custom-speech-audio-transcript-pairs.png)

Speech Service 구독에 권장되는 지역 목록은 [Azure 계정 설정](custom-speech-overview.md#set-up-your-azure-account)을 참조하세요. 이러한 지역 중 하나에서 Speech 구독을 설정하면 모델을 학습하는 데 걸리는 시간이 줄어듭니다. 다른 지역에서는 하루 1시간 정도의 오디오를 학습시키는 데 비해 이러한 지역에서는 하루 10시간 정도의 오디오를 학습할 수 있습니다. 1주일 이내에 모델 학습을 완료할 수 없는 경우 모델이 실패로 표시됩니다.

모든 기본 모델이 오디오 데이터를 통한 학습을 지원하지는 않습니다. 기본 모델이 지원하지 않는 경우 서비스는 오디오를 무시하고 대화 기록 텍스트로 학습합니다. 이 경우 학습은 관련 텍스트가 있는 학습과 동일합니다. 오디오 데이터를 통한 학습을 지원하는 기본 모델의 목록을 확인하려면 [언어 지원](language-support.md#speech-to-text)을 참조하세요.

## <a name="plain-text-data-for-training"></a>학습용 일반 텍스트 데이터

도메인 관련 문장을 사용하여 제품 이름 또는 산업별 전문 용어를 인식할 때 정확성을 향상시킬 수 있습니다. 단일 텍스트 파일에 문장을 제공합니다. 정확도를 높이기 위해 예상되는 음성 발화에 더 가까운 텍스트 데이터를 사용합니다. 

일반 텍스트를 사용한 학습은 일반적으로 몇 분 이내에 완료됩니다.

문장을 사용하여 사용자 지정 모델을 만들려면 샘플 발화 목록을 제공해야 합니다. 발화는 완전하거나 문법적으로 정확할 필요는 _없지만_ 프로덕션에서 기대하는 음성 입력을 정확하게 반영해야 합니다. 특정 용어의 가중치를 높이려면 특정 용어가 포함된 문장을 여러 개 추가합니다.

일반적으로 모델 적응은 학습 텍스트가 프로덕션에서 예상되는 실제 텍스트와 최대한 가까운 경우에 가장 효과적입니다. 개선하려는 도메인별 용어 및 구를 학습 텍스트에 포함해야 합니다. 가능하면 하나의 문장이나 키워드를 별도의 줄로 제어해 봅니다. 사용자에게 중요한 키워드 및 구(예: 제품 이름)의 경우 여러 번 복사할 수 있습니다. 그러나 너무 많이 복사하면 전반적인 인식 요금에 영향을 줄 수 있습니다.

이 표를 사용하여 발화에 대한 관련 데이터 파일의 형식이 올바른지 확인합니다.

| 속성 | 값 |
|----------|-------|
| 텍스트 인코딩 | UTF-8 BOM |
| 줄당 발언의 # | 1 |
| 최대 파일 크기 | 200MB |

또한 다음과 같은 제한 사항도 고려할 수 있습니다.

* 문자, 단어 또는 단어 그룹을 네 번 이상 반복하지 않습니다. 예를 들어 "aaaa", "yeah yeah yeah yeah", "that's it that's it that's it that's it" 등입니다. Speech Service는 반복이 너무 많은 줄을 삭제할 수 있습니다.
* `U+00A1`보다 높은 특수 문자나 UTF-8 문자는 사용하지 않습니다.
* URI는 거부됩니다.
* 일부 언어의 경우(예: 일본어 또는 한국어) 많은 양의 텍스트 데이터를 가져오는 데 시간이 오래 걸릴 수 있습니다. 업로드된 데이터를 각각 최대 20,000줄의 텍스트 파일로 분할하는 것이 좋습니다.

## <a name="pronunciation-data-for-training"></a>학습용 발음 데이터

사용자가 접하거나 사용하게 될 표준 발음이 없는 특수 용어가 있는 경우 사용자 지정 발음 파일을 제공하여 인식을 향상시킬 수 있습니다. 
> [!IMPORTANT]
> 사용자 지정 발음 파일을 사용하여 일반적인 단어의 발음을 변경하는 것은 권장되지 않습니다.

단일 텍스트 파일에 발음을 제공합니다. 여기에는 음성 발화의 예와 각각에 대한 사용자 지정 발음이 포함됩니다.

| 인식된/표시된 형식 | 발성 형식 |
|--------------|--------------------------|
| 3CPO | three c p o |
| CNTK | c n t k |
| IEEE | i triple e |

구어체는 철자로 풀어 쓴 음성 시퀀스로 문자, 단어, 음절 또는 세 가지 모두의 조합으로 구성될 수 있습니다.

사용자 지정 발음은 영어(`en-US`) 및 독일어(`de-DE`)에서 사용할 수 있습니다. 다음 표는 언어별로 지원되는 문자를 보여줍니다.

| 언어 | Locale | 문자 |
|----------|--------|------------|
| 영어 | `en-US` | `a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |
| 독일어 | `de-DE` | `ä, ö, ü, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z` |

다음 표를 사용하여 발음에 대한 관련 데이터 파일이 올바른 형식인지 확인합니다. 발음 파일은 작으며 크기는 몇 킬로바이트여야 합니다.

| 속성 | 값 |
|----------|-------|
| 텍스트 인코딩 | UTF-8 BOM(영어의 경우 ANSI도 지원됨) |
| 한 줄에 #개의 발음 | 1 |
| 최대 파일 크기 | 1MB(무료 계층의 경우 1KB) |

## <a name="audio-data-for-testing"></a>테스트용 오디오 데이터

오디오 데이터는 Microsoft의 기본 음성 텍스트 변환 모델 또는 사용자 지정 모델의 정확도를 테스트하는 데 가장 적합합니다. 오디오 데이터는 특정 모델의 성능과 관련하여 음성의 정확도를 검사하는 데 사용됩니다. 모델의 정확도를 수량화하려는 경우 [오디오 + 휴먼 레이블 대화 기록](#audio--human-labeled-transcript-data-for-trainingtesting)을 사용합니다.

Custom Speech에는 다음 속성을 가진 오디오 파일이 필요합니다.

| 속성                 | 값                 |
|--------------------------|-----------------------|
| 파일 형식              | RIFF(WAV)            |
| 샘플 속도              | 8,000Hz 또는 16,000Hz |
| 채널                 | 1(mono)              |
| 오디오 당 최대 길이 | 2시간               |
| 샘플 형식            | PCM, 16비트           |
| 보관 형식           | .zip                  |
| 최대 보관 크기     | 2GB                  |

[!INCLUDE [supported-audio-formats](includes/supported-audio-formats.md)]

> [!NOTE]
> 학습 및 테스트 데이터를 업로드할 때 .zip 파일 크기는 2GB를 초과할 수 없습니다. 학습에 더 많은 데이터가 필요할 경우 여러 개의 .zip 파일로 나눠 별도로 업로드합니다. 나중에 *여러* 데이터 세트에서 학습하도록 선택할 수 있습니다. 그러나 *단일* 데이터 세트에서만 테스트할 수 있습니다.

<a href="http://sox.sourceforge.net" target="_blank" rel="noopener">SoX</a>를 사용하여 오디오 속성을 확인하거나 기존 오디오를 적절한 형식으로 변환합니다. 다음은 몇 가지 SoX 명령 예제입니다.

| 활동 | SoX 명령 |
|---------|-------------|
| 오디오 파일 형식을 확인합니다. | `sox --i <filename>` |
| 오디오 파일을 단일 채널 16비트, 16KHz로 변환합니다. | `sox <input> -b 16 -e signed-integer -c 1 -r 16k -t wav <output>.wav` |

## <a name="next-steps"></a>다음 단계

* [데이터 검사](how-to-custom-speech-inspect-data.md)
* [데이터 평가](how-to-custom-speech-evaluate-data.md)
* [사용자 지정 모델 학습](how-to-custom-speech-train-model.md)
* [모델 배포](./how-to-custom-speech-train-model.md)
