---
title: 매핑 데이터 흐름 성능 및 조정 가이드
titleSuffix: Azure Data Factory & Azure Synapse
description: Azure Data Factory 및 Azure Synapse Analytics 파이프라인에서 매핑 데이터 흐름의 매핑 성능에 영향을 주는 주요 요소에 대해 알아봅니다.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.subservice: data-flows
ms.custom: synapse
ms.date: 06/07/2021
ms.openlocfilehash: 606b24662fba30e68a9195f19d63ec31f51f9221
ms.sourcegitcommit: 0046757af1da267fc2f0e88617c633524883795f
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/13/2021
ms.locfileid: "122642934"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>매핑 데이터 흐름 성능 및 조정 가이드

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Factory 및 Synapse 파이프라인의 매핑 데이터 흐름은 대규모로 데이터 변환을 설계하고 실행할 수 있는 코드 없는 인터페이스를 제공합니다. 매핑 데이터 흐름을 잘 모르는 경우 [매핑 데이터 흐름 개요](concepts-data-flow-overview.md)를 참조하세요. 이 문서에서는 성능 벤치마크를 충족하도록 데이터 흐름을 튜닝하고 최적화하는 다양한 방법을 중점적으로 설명합니다.

아래 비디오는 데이터 흐름을 사용하여 데이터를 변환하는 몇 가지 샘플 타이밍을 보여줍니다.

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="testing-data-flow-logic"></a>데이터 흐름 논리 테스트

UI에서 데이터 흐름을 디자인하고 테스트할 때 디버그 모드에서 라이브 Spark 클러스터를 대화형으로 테스트할 수 있습니다. 이렇게 하면 클러스터가 준비될 때까지 기다리지 않고 데이터를 미리 보고 데이터 흐름을 실행할 수 있습니다. 자세한 내용은 [디버그 모드](concepts-data-flow-debug-mode.md)를 참조하세요.

## <a name="monitoring-data-flow-performance"></a>데이터 흐름 성능 모니터링

디버그 모드를 사용하여 변환 논리를 확인한 후에는 데이터 흐름을 파이프라인의 작업으로써 처음부터 끝까지 테스트합니다. 데이터 흐름은 [데이터 흐름 작업 실행](control-flow-execute-data-flow-activity.md)을 사용하여 파이프라인에서 작동합니다. 데이터 흐름 작업에는 다른 작업과 달리 변환 논리의 자세한 실행 계획 및 성능 프로필을 표시하는 고유한 모니터링 환경이 있습니다. 데이터 흐름의 자세한 모니터링 정보를 보려면 파이프라인의 활동 실행 출력에서 안경 아이콘을 클릭합니다. 자세한 내용은 [매핑 데이터 흐름 모니터링](concepts-data-flow-monitoring.md)을 참조하세요.

![데이터 흐름 모니터링](media/data-flow/monitoring-details.png "데이터 흐름 모니터 2")

데이터 흐름 성능을 모니터링할 때 다음과 같은 네 가지 병목 현상을 살펴봐야 합니다.

* 클러스터 시작 시간
* 원본에서 읽기
* 변환 시간
* 싱크에 쓰기 

![데이터 흐름 모니터링](media/data-flow/monitoring-performance.png "데이터 흐름 모니터 3")

클러스터 시작 시간은 Apache Spark 클러스터를 가동하는 데 걸리는 시간입니다. 이 값은 모니터링 화면의 오른쪽 위 모서리에 있습니다. 데이터 흐름은 각 작업이 격리된 클러스터를 사용하는 Just-In-Time 모델에서 실행됩니다. 이 시작 시간은 일반적으로 3-5입니다. 순차적 작업의 경우 Time to Live 값을 사용하여 이 시간을 줄일 수 있습니다. 자세한 내용은 [Azure Integration Runtime 최적화](#ir)를 참조하세요.

데이터 흐름은 '스테이지'의 비즈니스 논리를 다시 정렬하고 실행하여 최대한 수행하는 Spark 최적화 프로그램을 활용합니다. 데이터 흐름에서 기록하는 각 싱크의 경우 모니터링 출력에는 싱크에 데이터를 쓰는 데 걸리는 시간과 함께 각 변환 단계의 기간이 나열됩니다. 가장 긴 시간은 데이터 흐름의 병목 상태를 의미할 수 있습니다. 가장 오래 걸리는 변환 단계에 원본이 포함된 경우 좀 더 자세히 살펴보고 읽기 시간을 최적화할 수 있습니다. 변환이 오래 걸리는 경우 통합 런타임을 다시 분할하거나 크기를 늘려야 할 수 있습니다. 싱크 처리가 오래 걸리는 경우 데이터베이스를 스케일 업하거나 단일 파일에 출력하고 있지는 않은지 확인해야 할 수 있습니다.

데이터 흐름의 병목 상태를 확인한 후에는 아래 최적화 전략을 사용하여 성능을 향상합니다.

## <a name="optimize-tab"></a>최적화 탭

**최적화** 탭에는 Spark 클러스터의 파티션 구성표를 구성하는 설정이 포함되어 있습니다. 이 탭은 데이터 흐름의 모든 변환에 있으며 변환이 완료된 **후** 데이터를 다시 분할할 것인지 여부를 지정합니다. 데이터 분할을 조정하면 전반적인 데이터 흐름 성능에 긍정적인 영향과 부정적인 영향을 모두 줄 수 있는 컴퓨팅 노드 간의 데이터 분산 및 데이터 위치 최적화를 제어할 수 있습니다.

![[파티션 옵션], [파티션 유형] 및 [파티션 수]로 구성된 [최적화] 탭을 보여주는 스크린샷](media/data-flow/optimize.png)

변환의 현재 출력 분할을 유지하도록 서비스에 지시하는 *현재 분할 사용* 이 기본적으로 선택됩니다. 데이터를 다시 분할하는 데 시간이 걸리므로 대부분의 시나리오에서는 *현재 분할 사용* 을 선택하는 것이 좋습니다. 데이터를 상당히 왜곡하는 집계 및 조인 이후 또는 SQL DB에서 원본 분할을 사용하는 경우 데이터를 다시 분할해야 할 수도 있습니다.

변환의 분할을 변경하려면 **최적화** 탭을 클릭하고 **분할 설정** 라디오 단추를 선택합니다. 그러면 일련의 분할 옵션이 표시됩니다. 최상의 분할 방법은 데이터 볼륨, 후보 키, null 값 및 카디널리티에 따라 다릅니다. 

> [!IMPORTANT]
> 단일 파티션은 모든 분산 데이터를 단일 파티션에 결합합니다. 이 작업은 모든 다운스트림 변환과 쓰기에 상당한 영향을 주는 매우 느린 작업입니다. 이 옵션은 이 옵션을 사용하는 것이 명시적인 비즈니스 이유가 없으면 사용하지 않는 것이 좋습니다.

다음 분할 옵션은 모든 변환에 사용할 수 있습니다.

### <a name="round-robin"></a>라운드 로빈 

라운드 로빈은 파티션 간에 데이터를 균등하게 분산 합니다. 견고하고 스마트한 분할 전략을 구현하기 위한 적절한 키 후보가 없는 경우 라운드 로빈을 사용합니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="hash"></a>해시

이 서비스는 유사한 값을 가진 행이 동일한 파티션에 속하도록 균일한 파티션을 생성하기 위해 열 해시를 생성합니다. 해시 옵션을 사용하는 경우 가능한 파티션 기울이기를 테스트합니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="dynamic-range"></a>동적 범위

동적 범위는 사용자가 제공하는 열 또는 식을 기반으로 하는 Spark 동적 범위를 사용합니다. 물리적 파티션 수를 설정할 수 있습니다. 

### <a name="fixed-range"></a>고정 범위

분할된 데이터 열의 값에 대한 고정 범위를 제공하는 식을 작성합니다. 파티션 기울이기를 방지하기 위해 이 옵션을 사용하기 전에 데이터를 잘 파악해야 합니다. 식에 대해 입력한 값이 파티션 함수의 일부로 사용됩니다. 물리적 파티션 수를 설정할 수 있습니다.

### <a name="key"></a>키

데이터의 카디널리티를 잘 알고 있는 경우 키 분할은 좋은 전략이 될 수 있습니다. 키 분할은 열의 각 고유 값에 대한 파티션을 만듭니다. 숫자가 데이터의 고유 값을 기반으로 하기 때문에 파티션 수를 설정할 수 없습니다.

> [!TIP]
> 파티션 구성표를 수동으로 설정하면 데이터가 다시 섞여서 Spark 최적화 프로그램의 이점이 상쇄될 수 있습니다. 꼭 필요한 경우를 제외하고 분할을 수동으로 설정하지 않는 것이 가장 좋습니다.

## <a name="logging-level"></a>로깅 수준

데이터 흐름 활동의 모든 파이프라인 실행에서 모든 자세한 원격 분석 로그를 완전히 기록할 필요가 없는 경우 필요에 따라 로깅 수준을 ‘기본’ 또는 ‘없음’으로 설정할 수 있습니다. '자세한 정보' 모드(기본값)에서 데이터 흐름을 실행하는 경우 서비스에 데이터 변환 중 각 개별 파티션 수준에서 작업을 완전히 기록하도록 요청하는 것입니다. 이 작업은 비용이 많이 들 수 있으므로 문제를 해결하는 경우에만 자세한 정보를 사용하면 전체 데이터 흐름 및 파이프라인 성능을 향상시킬 수 있습니다. ‘기본’ 모드에서는 변환 기간만 기록하고, ‘없음’의 경우 기간 요약만 제공합니다.

![로깅 수준](media/data-flow/logging.png "로깅 수준 설정")

## <a name="optimizing-the-azure-integration-runtime"></a><a name="ir"></a> Azure Integration Runtime 최적화

데이터 흐름은 런타임에 스핀업된 Spark 클러스터에서 실행됩니다. 사용되는 클러스터의 구성은 활동의 IR(통합 런타임)에 정의되어 있습니다. 통합 런타임을 정의할 때 클러스터 유형, 클러스터 크기 및 Time to Live의 세 가지 성능을 고려해야 합니다.

통합 런타임을 만드는 방법에 대한 자세한 내용은 [통합 런타임](concepts-integration-runtime.md)을 참조하세요.

### <a name="cluster-type"></a>클러스터 유형

Spark 클러스터 스핀업 유형에 사용할 수 있는 세 가지 옵션은 범용, 메모리 최적화 및 컴퓨팅 최적화입니다.

**범용** 클러스터는 기본적으로 선택되며 대부분의 데이터 흐름 워크로드에 이상적입니다. 성능과 비용의 균형이 가장 좋습니다.

데이터 흐름에서 조인과 조회가 많이 발생하는 경우 **메모리 최적화** 클러스터를 사용하는 것이 좋습니다. 메모리 최적화 클러스터는 메모리에 더 많은 데이터를 저장할 수 있으며 발생할 수 있는 메모리 부족 오류를 최소화합니다. 메모리 최적화 옵션은 코어당 가격이 가장 높지만 보다 성공적인 파이프라인을 만들 수 있습니다. 데이터 흐름을 실행할 때 메모리 부족 오류가 발생하면 메모리 최적화 Azure IR 구성으로 전환하세요. 

**컴퓨팅 최적화** 는 ETL 워크플로에 적합하지 않으며 대부분의 프로덕션 워크로드에 권장하지 않습니다. 데이터 필터링 또는 파생 열 추가와 같이 메모리를 많이 사용하지 않는 간단한 데이터 변형의 경우 코어당 가격이 저렴한 컴퓨팅 최적화 클러스터를 사용해도 됩니다.

### <a name="cluster-size"></a>클러스터 크기

데이터 흐름은 데이터 처리를 Spark 클러스터의 여러 노드에 분산하여 작업을 병렬로 수행합니다. 더 많은 코어가 있는 Spark 클러스터는 컴퓨팅 환경에서 노드 수를 늘립니다. 노드가 많을수록 데이터 흐름의 처리 성능이 향상됩니다. 클러스터 크기를 늘리면 처리 시간이 단축되는 경우가 많습니다.

기본 클러스터 크기는 드라이버 노드 4개와 작업자 노드 4개입니다.  더 많은 데이터를 처리하는 경우 더 큰 클러스터를 사용하는 것이 좋습니다. 아래는 사용 가능한 크기 옵션입니다.

| 작업자 코어 | 드라이버 코어 | 총 코어 | 참고 |
| ------------ | ------------ | ----------- | ----- |
| 4 | 4 | 8 | 컴퓨팅 최적화에는 사용할 수 없음 |
| 8 | 8 | 16 | |
| 16 | 16 | 32 | |
| 32 | 16 | 48 | |
| 64 | 16 | 80 | |
| 128 | 16 | 144 | |
| 256 | 16 | 272 | |

데이터 흐름은 vCore-시간으로 가격이 책정됩니다. 즉, 클러스터 크기와 실행 시간을 모두 고려합니다. 스케일 업하면 분당 클러스터 비용이 증가하지만 전체 시간이 감소합니다.

> [!TIP]
> 클러스터 크기가 데이터 흐름의 성능에 영향을 미치는 한계가 있습니다. 데이터의 크기에 따라 클러스터 크기를 늘려도 성능이 더 이상 향상되지 않는 지점이 있습니다. 예를 들어 데이터 파티션보다 노드가 더 많은 경우 노드를 더 추가해도 도움이 되지 않습니다. 작게 시작하고 이후에 성능 요구 사항에 맞게 스케일 업하는 것이 가장 좋습니다. 

### <a name="time-to-live"></a>TTL(Time to live)

기본적으로 모든 데이터 흐름 작업은 Azure IR 구성에 따라 새 Spark 클러스터를 스핀업합니다. 콜드 클러스터 시작 시간은 몇 분 정도 걸리며 완료될 때까지 데이터 처리를 시작할 수 없습니다. 파이프라인에 여러 개의 **순차적** 데이터 흐름이 포함된 경우 TTL(Time to Live) 값을 사용할 수 있습니다. Time to Live 값을 지정하면 실행이 완료된 후에도 특정 기간 동안 클러스터가 활성 상태로 유지됩니다. TTL 시간 동안 IR을 사용하여 새 작업이 시작되면 기존 클러스터를 다시 사용하므로 시작 시간이 크게 단축됩니다. 두 번째 작업이 완료되면 클러스터는 다시 TTL 시간 동안 활성 상태로 유지됩니다.

데이터 흐름 속성 아래의 Azure 통합 런타임에 있는 “빠른 다시 사용” 옵션을 설정하여 웜 클러스터의 시작 시간을 추가로 최소화할 수 있습니다. 이를 참으로 설정하면 각 작업 후에 기존 클러스터를 해체하지 않고 기존 클러스터를 다시 사용하도록, 특히 Azure IR에서 설정한 컴퓨팅 환경을 TTL에 지정된 기간까지 활성 상태로 유지하도록 서비스에 지시하게 됩니다. 이 옵션을 사용하면 파이프라인에서 실행될 때 데이터 흐름 활동의 시작 시간이 가장 짧습니다.

그러나 대부분의 데이터 흐름이 병렬로 실행되는 경우 해당 활동에 사용하는 IR에 대해 TTL을 사용하지 않는 것이 좋습니다. 단일 클러스터에서 한 번에 하나의 작업만 실행할 수 있습니다. 사용 가능한 클러스터가 있지만 두 개의 데이터 흐름이 시작되면 하나만 라이브 클러스터를 사용합니다. 두 번째 작업은 자체 격리된 클러스터를 스핀업합니다.

> [!NOTE]
> 자동 해결 통합 런타임을 사용하는 경우 Time to Live를 사용할 수 없습니다.
 
## <a name="optimizing-sources"></a>원본 최적화

Azure SQL Database를 제외한 모든 원본은 **현재 분할 사용** 을 계속 유지하는 것이 좋습니다. 다른 모든 원본 시스템에서 데이터를 읽을 때 데이터 흐름은 데이터 크기에 따라 자동으로 데이터를 균등하게 분할합니다. 128MB 데이터마다 새 파티션이 만들어집니다. 데이터 크기가 증가하면 파티션 수도 증가합니다.

사용자 지정 분할은 Spark가 데이터를 읽은 *후에* 발생하며 데이터 흐름 성능에 부정적인 영향을 줍니다. 읽기 시에 데이터가 균등하게 분할되므로 권장하지 않습니다. 

> [!NOTE]
> 원본 시스템의 처리량에 따라 읽기 속도가 제한될 수 있습니다.

### <a name="azure-sql-database-sources"></a>Azure SQL Database 원본

Azure SQL Database에는 '원본' 분할이라는 고유한 분할 옵션이 있습니다. 원본 시스템에서 병렬 연결을 사용하도록 설정하면 원본 분할을 사용하여 Azure SQL DB에서 데이터를 읽는 시간을 향상할 수 있습니다. 파티션 수를 지정하고 데이터 분할 방법을 지정합니다. 카디널리티가 높은 파티션 열을 사용합니다. 원본 테이블의 파티션 구성표와 일치하는 쿼리를 입력할 수도 있습니다.

> [!TIP]
> 원본 분할의 경우 SQL Server I/O는 병목 상태입니다. 너무 많은 파티션을 추가하면 원본 데이터베이스가 포화될 수 있습니다. 일반적으로 이 옵션을 사용하는 경우 파티션 4개 또는 5개가 적절합니다.

![원본 분할](media/data-flow/sourcepart3.png "원본 분할")

#### <a name="isolation-level"></a>격리 수준

Azure SQL 원본 시스템에서 읽기의 격리 수준은 성능에 영향을 줍니다. '커밋되지 않은 읽기'를 선택하면 가장 빠른 성능이 제공되고 데이터베이스 잠금이 방지됩니다. SQL 격리 수준에 대한 자세한 내용은 [격리 수준 이해](/sql/connect/jdbc/understanding-isolation-levels)를 참조하세요.

#### <a name="read-using-query"></a>쿼리를 사용하여 읽기

테이블 또는 SQL 쿼리를 사용하여 Azure SQL Database에서 읽을 수 있습니다. SQL 쿼리를 실행하는 경우 쿼리를 완료한 후 변환을 시작해야 합니다. SQL 쿼리는 SELECT, WHERE 및 JOIN 문과 같이 더 빠르게 실행되고 SQL Server에서 읽는 데이터 양을 줄일 수 있는 작업을 푸시하는 데 유용합니다. 작업을 푸시하면 데이터가 데이터 흐름으로 들어오기 전에는 변환의 계보 및 성능을 추적하는 기능을 사용할 수 없습니다.

### <a name="azure-synapse-analytics-sources"></a>Azure Synapse Analytics 원본

Azure Synapse Analytics를 사용하는 경우 원본 옵션에 **준비 사용** 이라는 설정이 있습니다. 이 설정을 사용하면 서비스가 ```Staging```을 사용하여 Azure Synapse의 데이터를 읽을 수 있으므로 읽기 성능이 크게 향상됩니다. ```Staging```을 사용하려면 데이터 흐름 활동 설정에서 Azure Blob Storage 또는 Azure Data Lake Storage gen2 준비 위치를 지정해야 합니다.

![준비 사용](media/data-flow/enable-staging.png "준비 사용")

### <a name="file-based-sources"></a>파일 기반 원본

데이터 흐름은 다양한 파일 형식을 지원하지만 읽기 및 쓰기 시간이 최적화되도록 Spark 네이티브 Parquet 형식을 사용하는 것이 좋습니다.

파일 세트에서 동일한 데이터 흐름을 실행하는 경우 와일드 카드 경로를 사용하여 폴더에서 읽거나 파일 목록에서 읽는 것이 좋습니다. 단일 데이터 흐름 활동 실행은 모든 파일을 일괄 처리로 처리할 수 있습니다. 이러한 설정을 지정하는 방법에 대한 자세한 내용은 [Azure Blob Storage](connector-azure-blob-storage.md#source-transformation)와 같은 커넥터 설명서에서 찾을 수 있습니다.

되도록이면 For-Each 활동을 사용하여 파일 세트에 대한 데이터 흐름을 실행하지 마세요. 이렇게 하면 for-each의 각 반복이 자체 Spark 클러스터를 스핀업하게 되는데, 필요 없는 경우가 많고 비용이 많이 발생할 수 있습니다. 

## <a name="optimizing-sinks"></a>싱크 최적화

데이터 흐름이 싱크에 기록될 때 사용자 지정 분할은 쓰기 직전에 발생합니다. 원본과 마찬가지로 대부분의 경우 **현재 분할 사용** 을 파티션 옵션으로 계속 유지하는 것이 좋습니다. 분할된 데이터는 대상이 분할되지 않은 경우에도 분할되지 않은 데이터보다 쓰기 속도가 훨씬 빠릅니다. 아래는 다양한 싱크 유형의 개별 고려 사항입니다. 

### <a name="azure-sql-database-sinks"></a>Azure SQL Database 싱크

Azure SQL Database를 사용하면 대부분의 경우 기본 분할이 작동합니다. SQL 데이터베이스에서 처리하기에 너무 많은 파티션이 싱크에 포함될 가능성이 있습니다. 이 경우 SQL Database 싱크에서 출력하는 파티션 수를 줄입니다.

#### <a name="impact-of-error-row-handling-to-performance"></a>오류 행 처리가 성능에 미치는 영향

싱크 변환에서 오류 행 처리("오류 발생 시 계속")를 사용하도록 설정하면 서비스는 대상 테이블에 호환되는 행을 쓰기 전에 추가 단계를 수행합니다. 이 추가 단계를 수행하면 5% 범위에서 약간의 성능 저하가 발생할 수 있으며, 호환되지 않는 행을 로그 파일에 쓰도록 옵션을 설정한 경우에도 약간의 성능이 추가로 저하됩니다.

#### <a name="disabling-indexes-using-a-sql-script"></a>SQL 스크립트를 사용하여 인덱스 비활성화

SQL 데이터베이스에 로드하기 전에 인덱스를 비활성화하면 테이블에 쓰기 성능이 크게 향상됩니다. SQL 싱크에 쓰기 전에 아래 명령을 실행합니다.

`ALTER INDEX ALL ON dbo.[Table Name] DISABLE`

쓰기가 완료되면 다음 명령을 사용하여 인덱스를 다시 작성합니다.

`ALTER INDEX ALL ON dbo.[Table Name] REBUILD`

두 가지 작업 모두 매핑 데이터 흐름의 Azure SQL DB 또는 Synapse 싱크 내에서 SQL 사전 및 사후 SQL 스크립트를 사용하여 수행할 수 있습니다.

![인덱스 사용 안 함](media/data-flow/disable-indexes-sql.png "인덱스 사용 안 함")

> [!WARNING]
> 인덱스를 사용하지 않도록 설정하면 데이터 흐름이 데이터베이스를 효과적으로 제어하며 이 시점에는 쿼리가 성공할 가능성이 거의 없습니다. 결과적으로 이 충돌을 방지하기 위해 많은 ETL 작업이 야간에 트리거됩니다. 자세한 내용은 [인덱스 비활성화의 제약 조건](/sql/relational-databases/indexes/disable-indexes-and-constraints)을 참조하세요.

#### <a name="scaling-up-your-database"></a>데이터베이스 스케일 업

일단 DTU 한도에 도달하면, 파이프라인 실행 전에 원본 크기 조정을 예약하고 Azure SQL DB 및 DW를 싱크하여 처리량을 늘리고 Azure 제한을 최소화합니다. 파이프라인 실행이 완료되면 데이터베이스를 다시 일반 실행 속도로 조정합니다.

### <a name="azure-synapse-analytics-sinks"></a>Azure Synapse Analytics 싱크

Azure Synapse Analytics에 쓸 때 **준비 사용** 을 true로 설정해야 합니다. 이렇게 하면 서비스가 대량의 데이터를 효과적으로 로드하는 [SQL 복사 명령](/sql/t-sql/statements/copy-into-transact-sql)을 사용하여 쓸 수 있습니다. 준비를 사용하는 경우 데이터 준비를 위해 Azure Data Lake Storage gen2 또는 Azure Blob Storage 계정을 참조해야 합니다.

준비 외에도, Azure SQL Database와 동일한 모범 사례가 Azure Synapse Analytics에 적용됩니다.

### <a name="file-based-sinks"></a>파일 기반 싱크 

데이터 흐름은 다양한 파일 형식을 지원하지만 읽기 및 쓰기 시간이 최적화되도록 Spark 네이티브 Parquet 형식을 사용하는 것이 좋습니다.

데이터가 균등하게 분산되는 경우 파일 쓰기에 대한 가장 빠른 분할 옵션은 **현재 분할 사용** 입니다.

#### <a name="file-name-options"></a>파일 이름 옵션

파일을 쓸 때 이름 지정 옵션을 선택할 수 있으며 각 옵션은 성능에 영향을 줍니다.

![싱크 옵션](media/data-flow/file-sink-settings.png "싱크 옵션")

**기본값** 옵션을 선택하면 가장 빠르게 씁니다. 각 파티션은 Spark 기본 이름을 사용하는 파일을 동일하게 취급합니다. 이는 데이터 폴더에서 읽기만 하는 경우에 유용합니다.

이름 지정 **패턴** 을 설정하면 각 파티션 파일의 이름이 사용자에게 친숙한 이름으로 바뀝니다. 이 작업은 쓰기 후에 수행되며 기본값을 선택할 때보다 약간 느립니다. 파티션마다 개별 파티션의 이름을 수동으로 지정할 수 있습니다.

열이 데이터를 출력하는 방법에 해당하는 경우 **열의 데이터로** 를 선택할 수 있습니다. 그러면 데이터가 섞이고 열이 균등하게 분산되지 않은 경우에는 성능에 영향을 줄 수 있습니다.

**단일 파일로 출력** 은 모든 데이터를 단일 파티션에 결합합니다. 이렇게 하면 데이터 세트의 크기가 클수록 쓰기 시간이 오래 걸립니다. 이 옵션은 이 옵션을 사용하는 것이 명시적인 비즈니스 이유가 없으면 사용하지 않는 것이 좋습니다.

### <a name="cosmosdb-sinks"></a>CosmosDB 싱크

CosmosDB에 쓸 때 데이터 흐름이 실행되는 동안 처리량과 일괄 처리 크기를 변경하면 성능이 향상될 수 있습니다. 이러한 변경 내용은 데이터 흐름 활동 실행 중에만 적용되며 완료 후에 원래 컬렉션 설정으로 돌아갑니다. 

**일괄 처리 크기:** 일반적으로 기본 일괄 처리 크기로 시작하는 것으로 충분합니다. 이 값을 추가로 튜닝하려면 데이터의 대략적인 개체 크기를 계산하고, 개체 크기 * 일괄 처리 크기가 2MB 미만인지 확인합니다. 미만이면 일괄 처리 크기를 늘려서 처리량을 높일 수 있습니다.

**처리량**: 여기서 더 높은 처리량을 설정하여 CosmosDB에 문서를 더 빨리 쓸 수 있습니다. 처리량을 높게 설정하면 더 많은 RU 비용이 발생합니다.

**쓰기 처리량 예산**: 분당 총 RU보다 작은 값을 사용합니다. 많은 수의 Spark 파티션이 포함된 데이터 흐름이 있는 경우 예산 처리량을 설정하여 모든 파티션에 부하를 분산할 수 있습니다.

## <a name="optimizing-transformations"></a>변환 최적화

### <a name="optimizing-joins-exists-and-lookups"></a>조인, 존재 및 조회 최적화

#### <a name="broadcasting"></a>브로드캐스트

조인, 조회 및 존재 변환에서 하나 또는 두 데이터 스트림이 작업자 노드 메모리에 적합한 작은 크기인 경우 **브로드캐스트** 를 사용하도록 설정하여 성능을 최적화할 수 있습니다. 브로드캐스트를 사용하면 클러스터의 모든 노드에 작은 데이터 프레임을 보내게 됩니다. 그러면 Spark 엔진은 대규모 스트림의 데이터를 다시 섞지 않고도 조인을 수행할 수 있습니다. 기본적으로 spark 엔진은 조인의 한 쪽에서 브로드캐스트할지 여부를 자동으로 결정합니다. 들어오는 데이터에 대해 잘 알고 있고 한 스트림이 다른 스트림보다 많이 작을 것이라는 사실을 알고 있는 경우 **고정** 브로드캐스트를 선택할 수 있습니다. 고정 브로드캐스트는 선택한 스트림을 Spark에서 브로드캐스트하게 합니다. 

브로드캐스트된 데이터의 크기가 Spark 노드에 비해 너무 크면 메모리 부족 오류가 발생할 수 있습니다. 메모리 부족 오류를 방지하려면 **메모리 최적화** 클러스터를 사용합니다. 데이터 흐름을 실행하는 동안 브로드캐스트 시간 제한이 발생하는 경우 브로드캐스트 최적화를 해제하면 됩니다. 그러나 이로 인해 데이터 흐름이 더 느리게 수행됩니다.

큰 데이터베이스 쿼리와 같이 쿼리하는 데 더 오래 걸릴 수 있는 데이터 원본으로 작업하는 경우 조인에 대해 브로드캐스트를 끄는 것이 좋습니다. 원본의 쿼리 시간이 길면 클러스터가 컴퓨팅 노드에 브로드캐스트를 시도할 때 Spark 시간 초과가 발생할 수 있습니다. 나중에 조회 변환에 사용하기 위해 값을 집계하는 스트림이 데이터 흐름에 있는 경우에도 브로드캐스트를 끄는 것이 좋습니다. 이 패턴은 Spark 최적화 프로그램을 혼동시키고 시간 초과를 일으킬 수 있습니다.

![조인 변환 최적화](media/data-flow/joinoptimize.png "조인 최적화")

#### <a name="cross-joins"></a>크로스 조인

조인 조건에 리터럴 값을 사용하거나 조인의 양쪽에 일치 항목이 여러 개 있는 경우 Spark는 조인을 크로스 조인으로 실행합니다. 크로스 조인은 조인된 값을 필터링하는 완전한 카티전 곱입니다. 크로스 조인은 다른 조인 형식보다 많이 느립니다. 성능에 영향을 주지 않도록 조인 조건의 양쪽에 열 참조가 있어야 합니다.

#### <a name="sorting-before-joins"></a>조인 전 정렬

SSIS와 같은 도구의 병합 조인과 달리, 조인 변환은 필수 병합 조인 작업이 아닙니다. 조인 키를 변환하기 전에 정렬할 필요가 없습니다. 데이터 흐름을 매핑할 때는 정렬 변환을 사용하지 않는 것이 좋습니다.

### <a name="window-transformation-performance"></a>창 변환 성능

[창 변환](data-flow-window.md)은 변환 설정의 ```over()``` 절에서 선택하는 열 값을 기준으로 데이터를 분할합니다. Windows 변환에는 많은 사람들이 사용하는 다양한 집계 및 분석 함수가 있습니다. 그러나 순위 지정 ```rank()``` 또는 행 번호 ```rowNumber()```를 목적으로 전체 데이터 세트에 대한 창을 생성해야 하는 경우에는 [순위 변환](data-flow-rank.md) 및 [서로게이트 키 변환](data-flow-surrogate-key.md)을 대신 사용하는 것이 좋습니다. 이러한 변환은 해당 함수를 사용하여 전체 데이터 세트 작업을 보다 효율적으로 다시 수행합니다.

### <a name="repartitioning-skewed-data"></a>기울어진 데이터 다시 분할

조인 및 집계와 같은 특정 변환은 데이터 파티션을 다시 섞으며, 이로 인해 경우에 따라 데이터가 기울어질 수 있습니다. 데이터가 기울어졌다는 것은 데이터가 모든 파티션에 균등하게 분산되지 않았다는 뜻입니다. 데이터가 많이 기울어지면 다운스트림 변환 및 싱크 쓰기 속도가 저하될 수 있습니다. 데이터 흐름 실행의 모든 시점에서 모니터링 표시의 변환을 클릭하여 데이터 왜도를 확인할 수 있습니다.

![왜도 및 첨도](media/data-flow/skewness-kurtosis.png "왜도 및 첨도")

모니터링 표시에는 왜도 및 첨도 메트릭과 함께 각 파티션에 데이터가 분산되는 방식이 표시됩니다. **왜도** 는 데이터에 허용되는 비대칭성과 데이터가 양수, 0, 음수 또는 정의되지 않은 값을 가질 수 있는지 여부를 측정하는 방법입니다. 음수 기울이기는 왼쪽 꼬리가 오른쪽보다 긴 것을 의미합니다. **첨도** 는 데이터 꼬리가 굵은지 아니면 얇은지 측정하는 방법입니다. 높은 첨도 값은 바람직하지 않습니다. 적절한 왜도 범위는 -3에서 3 사이이고 첨도 범위는 10 미만입니다. 이러한 숫자를 해석하는 쉬운 방법은 파티션 차트를 살펴보고 1개 막대가 나머지 막대보다 유달리 큰지 확인하는 것입니다.

변환 후 데이터가 균등하게 분할되지 않으면 [최적화 탭](#optimize-tab)을 사용하여 다시 분할할 수 있습니다. 데이터를 다시 섞는 데 시간이 걸리고 데이터 흐름 성능이 향상되지 않을 수 있습니다.

> [!TIP]
> 데이터를 다시 분할하지만 데이터를 다시 섞는 다운스트림 변환이 있는 경우 조인 키로 사용되는 열에서 해시 분할을 사용합니다.

## <a name="using-data-flows-in-pipelines"></a>파이프라인에서 데이터 흐름 사용 

여러 데이터 흐름이 있는 복잡한 파이프라인을 빌드할 때 논리 흐름은 타이밍과 비용에 큰 영향을 줄 수 있습니다. 이 섹션에서는 다양한 아키텍처 전략의 영향에 대해 설명합니다.

### <a name="executing-data-flows-in-parallel"></a>병렬로 데이터 흐름 실행

여러 데이터 흐름을 병렬로 실행하는 경우 서비스는 각 활동에 대해 별도의 Spark 클러스터를 스핀업합니다. 이렇게 하면 각 작업을 격리하여 병렬로 실행할 수 있지만 여러 클러스터가 동시에 실행됩니다.

데이터 흐름이 병렬로 실행되는 경우 Azure IR Time to Live 속성을 사용하도록 설정하면 사용되지 않는 여러 웜 풀이 발생하므로 사용하지 않는 것이 좋습니다.

> [!TIP]
> 각 활동에 대해 동일한 데이터 흐름을 여러 번 실행하는 대신, 데이터 레이크에 데이터를 준비하고 와일드 카드 경로를 사용하여 단일 데이터 흐름에서 데이터를 처리합니다.

### <a name="execute-data-flows-sequentially"></a>순차적으로 데이터 흐름 실행

데이터 흐름 활동을 순서대로 실행하는 경우 Azure IR 구성에서 TTL을 설정하는 것이 좋습니다. 그러면 서비스가 컴퓨팅 리소스를 다시 사용하므로 클러스터가 더 빠르게 시작됩니다. 각 활동은 계속 격리되어 각 실행에 대한 새 Spark 컨텍스트를 수신합니다. 순차적인 활동 간의 시간을 더 줄이려면 Azure IR에서 “빠른 다시 사용” 확인란을 설정하여 기존 클러스터를 다시 사용하도록 서비스에 지시합니다.

### <a name="overloading-a-single-data-flow"></a>단일 데이터 흐름 오버로드

모든 논리를 단일 데이터 흐름 내에 배치하면 서비스는 전체 작업을 단일 Spark 인스턴스에서 실행합니다. 이는 비용을 절감하는 방법처럼 보일 수 있지만, 여러 논리 흐름이 뒤섞이기 때문에 모니터링 및 디버그가 어려울 수 있습니다. 한 구성 요소에서 오류가 발생하면 작업의 다른 부분도 모두 실패합니다. 비즈니스 논리의 독립적인 흐름을 기준으로 데이터 흐름을 구성하는 것이 좋습니다. 데이터 흐름이 너무 큰 경우 여러 독립 구성 요소로 분할하면 모니터링 및 디버깅이 더 쉬워집니다. 데이터 흐름의 변환 수에 대한 하드 한도는 없지만 너무 많으면 작업이 복잡해집니다.

### <a name="execute-sinks-in-parallel"></a>병렬로 싱크 실행

데이터 흐름 싱크의 기본 동작은 각 싱크를 순차적으로 실행하고 싱크에서 오류가 발생할 경우 데이터 흐름을 실패시키는 것입니다. 또한 데이터 흐름 속성으로 이동하여 싱크에 대해 다른 우선 순위를 설정하지 않는 한 모든 싱크는 기본적으로 동일한 그룹으로 지정됩니다.

데이터 흐름을 사용하면 UI 디자이너의 데이터 흐름 속성 탭에서 싱크를 그룹으로 묶을 수 있습니다. 동일한 그룹 번호를 사용하여 싱크의 실행 순서를 설정하고 싱크를 그룹으로 묶을 수 있습니다. 그룹을 쉽게 관리할 수 있도록 서비스에 동일한 그룹의 싱크를 병렬로 실행하도록 요청할 수 있습니다.

파이프라인 실행 데이터 흐름 활동의 "싱크 속성" 섹션에는 병렬 싱크 로드를 설정하는 옵션이 있습니다. "병렬로 실행"을 설정하면 데이터 흐름은 연결된 싱크에 순차적으로 쓰지 않고 동시에 씁니다. 병렬 옵션을 사용하려면 싱크를 그룹으로 묶고 새 분기 또는 조건부 분할을 통해 동일한 스트림에 연결해야 합니다.

## <a name="next-steps"></a>다음 단계

성능과 관련된 다음과 같은 다른 데이터 흐름 문서를 참조하세요.

- [데이터 흐름 작업](control-flow-execute-data-flow-activity.md)
- [데이터 흐름 성능 모니터링](concepts-data-flow-monitoring.md)
