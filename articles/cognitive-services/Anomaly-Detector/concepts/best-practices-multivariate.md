---
title: Anomaly Detector 다변량 API 사용 모범 사례
titleSuffix: Azure Cognitive Services
description: Anomaly Detector 다변량 API를 사용하여 시계열 데이터에 변칙 검색을 적용하는 모범 사례입니다.
services: cognitive-services
author: mrbullwinkle
manager: nitinme
ms.service: cognitive-services
ms.subservice: anomaly-detector
ms.topic: conceptual
ms.date: 04/01/2021
ms.author: mbullwin
keywords: 변칙 검색, 기계 학습, 알고리즘
ms.openlocfilehash: 4114771276f4fec6dfef0e953ef9f52e165db510
ms.sourcegitcommit: 6ea4d4d1cfc913aef3927bef9e10b8443450e663
ms.translationtype: HT
ms.contentlocale: ko-KR
ms.lasthandoff: 07/05/2021
ms.locfileid: "113297343"
---
# <a name="best-practices-for-using-the-anomaly-detector-multivariate-api"></a>Anomaly Detector 다변량 API 사용 모범 사례

이 문서에서는 다변량 Anomaly Detector(MVAD) API를 사용할 때 따라야 하는 권장 사례에 관한 지침을 제공합니다. 이 자습서에서는 다음을 수행합니다.

> [!div class="checklist"]
> * **API 사용**: 오류 없이 MVAD를 사용하는 방법을 알아봅니다.
> * **데이터 엔지니어링**: MVAD가 더 정확하게 수행되도록 데이터를 가장 잘 준비하는 방법을 알아봅니다.
> * **공통 문제**: 고객에게 발생하는 공통 문제를 방지하는 방법을 알아봅니다.
> * **FAQ**: 자주 묻는 질문에 관해 알아봅니다.

## <a name="api-usage"></a>API 사용

이 섹션의 지침에 따라 MVAD를 사용하는 동안 오류를 방지합니다. 그래도 오류가 발생하는 경우 관련 설명과 취할 조치는 [오류 코드의 전체 목록](./troubleshoot.md)을 참조하세요.

[!INCLUDE [mvad-input-params](../includes/mvad-input-params.md)]

[!INCLUDE [mvad-data-schema](../includes/mvad-data-schema.md)]


## <a name="data-engineering"></a>데이터 엔지니어링

이제 오류 없이 MVAD API를 사용하여 코드를 실행할 수 있습니다. 모델 정확도를 향상하기 위해 수행할 수 있는 작업은 무엇인가요?

### <a name="data-quality"></a>데이터 품질

* 모델이 기록 데이터에서 정상 패턴을 학습할 때 학습 데이터는 시스템의 **전체적인 정상** 상태를 나타내야 합니다. 학습 데이터가 변칙으로 가득 찬 경우 모델은 이 유형의 패턴을 학습하기 어렵습니다. 양호한 정확도를 보장하려면 비정상적인 비율의 경험적 임계값은 **1%** 이하입니다.
* 일반적으로 **학습 데이터의 누락된 값 비율은 20% 미만** 이어야 합니다. 누락된 데이터가 너무 많으면 자동으로 채워진 값(일반적으로 선형 값이나 상수 값)이 일반 패턴으로 학습될 수 있습니다. 이로 인해 실제(누락되지 않은) 데이터 포인트가 변칙으로 검색될 수 있습니다.
    그러나 높은 누락 비율이 허용될 수 있는 경우가 있습니다. 예를 들어, `Outer` 모드를 사용하여 타임스탬프를 정렬하는 두 개의 변수(시계열)가 그룹에 있는 경우입니다. 변수 중 하나는 1분 단위로 세분화되어 있고 다른 하나는 시간 단위로 세분화되어 있습니다. 그러면 기본적으로 시간별 변수에는 최소 59/60 = 98.33%의 누락된 데이터 포인트가 있습니다. 이 경우 사용할 수 있는 유일한 (누락되지 않은) 값이 일반적으로 너무 많이 변동하지 않는 경우 이 값을 사용하여 시간별 변수를 채우면 됩니다.

### <a name="data-quantity"></a>데이터 수량

* MVAD의 기본 모델에는 수백만 개의 매개 변수가 있습니다. 최적 매개 변수 세트를 학습하려면 최소 개수의 데이터 포인트가 필요합니다. 경험적 규칙은 양호한 정확도를 보장하기 위해 **변수당 15,000개 이상의 데이터 포인트(타임스탬프)** 를 제공하여 모델을 학습시켜야 한다는 것입니다. 일반적으로 학습 데이터가 많을수록 정확도가 향상됩니다. 그러나 많은 데이터를 누적할 수 없는 경우에도 적은 데이터로 실험하고 손상된 정확도가 허용되는지 확인하는 것이 좋습니다.
* 유추 API를 호출할 때마다 원본 데이터 파일에 충분한 데이터 포인트가 포함되는지 확인해야 합니다. 이는 일반적으로 `slidingWindow` + **실제로** 유추 결과가 필요한 데이터 포인트 수입니다. 예를 들어, **하나** 의 새 타임스탬프에서 유추하려고 할 때마다 데이터 파일에 선행 `slidingWindow` + **하나** 의 데이터 포인트가 포함될 수 있는 스트리밍 사례에서는 계속 이동하고, 데이터 포인트 수는 동일하지만(`slidingWindow` + 1) 하나의 단계를 “오른”쪽으로 이동하여 또 다른 zip 파일을 만들고, 또 다른 유추 작업을 위해 제출할 수 있습니다. 

    해당 값을 초과하는 항목이나 선행 슬라이딩 윈도우 “이전” 항목은 유추 결과에 전혀 영향을 주지 않으며 성능 다운그레이드만 발생시킬 수 있습니다. 해당 값 미만의 항목은 `NotEnoughInput` 오류를 초래할 수 있습니다.


### <a name="timestamp-round-up"></a>타임스탬프 반올림

변수 그룹(시계열)에서 각 변수는 독립적인 원본에서 수집될 수 있습니다. 서로 다른 변수의 타임스탬프가 서로 일치하지 않고 알려진 빈도와 일치하지 않을 수 있습니다. 다음은 간단한 예제입니다.

*Variable-1*

| timestamp | 값 |
| --------- | ----- |
| 12:00:01  | 1.0   |
| 12:00:35  | 1.5   |
| 12:01:02  | 0.9   |
| 12:01:31  | 2.2   |
| 12:02:08  | 1.3   |

*Variable-2*

| timestamp | 값 |
| --------- | ----- |
| 12:00:03  | 2.2   |
| 12:00:37  | 2.6   |
| 12:01:09  | 1.4   |
| 12:01:34  | 1.7   |
| 12:02:04  | 2.0   |

30초마다 데이터 포인트를 하나 전송하는 센서 두 개에서 수집된 변수 두 개가 있습니다. 그러나 센서는 정확하게 균일한 빈도로 데이터 포인트를 전송하는 것이 아니라 경우에 따라 더 이르게 전송하고 더 늦게 전송합니다. MVAD는 서로 다른 변수 간 상관 관계를 고려하므로 메트릭이 시스템의 조건을 올바르게 반영할 수 있도록 타임스탬프를 올바르게 정렬해야 합니다. 위 예제에서 변수 1과 변수 2의 타임스탬프는 정렬 전 빈도로 올바르게 ‘반올림’되어야 합니다.

전처리되지 않은 경우 어떻게 되는지 살펴보겠습니다. `alignMode`를 `Outer`(두 세트의 합집합을 의미함)로 설정하면 병합된 테이블은 다음과 같습니다.

| timestamp | Variable-1 | Variable-2 |
| --------- | -------- | -------- |
| 12:00:01  | 1.0      | `nan`    |
| 12:00:03  | `nan`    | 2.2      |
| 12:00:35  | 1.5      | `nan`    |
| 12:00:37  | `nan`    | 2.6      |
| 12:01:02  | 0.9      | `nan`    |
| 12:01:09  | `nan`    | 1.4      |
| 12:01:31  | 2.2      | `nan`    |
| 12:01:34  | `nan`    | 1.7      |
| 12:02:04  | `nan`    | 2.0      |
| 12:02:08  | 1.3      | `nan`    |

`nan`은 누락된 값을 나타냅니다. 물론 병합된 테이블은 예상과 다를 수 있습니다. 변수 1과 변수 2가 인터리빙되고 MVAD 모델은 변수 간 상관 관계에 관한 정보를 추출할 수 없습니다. `alignMode`를 `Inner`로 설정하면 변수 1과 변수 2에 공통 타임스탬프가 없으므로 병합된 테이블이 비게 됩니다.

따라서 변수 1과 변수 2의 타임스탬프는 전처리되어야 하며(가장 가까운 30초 타임스탬프로 반올림됨) 새 시계열은 다음과 같습니다.

*Variable-1*

| timestamp | 값 |
| --------- | ----- |
| 12:00:00  | 1.0   |
| 12:00:30  | 1.5   |
| 12:01:00  | 0.9   |
| 12:01:30  | 2.2   |
| 12:02:00  | 1.3   |

*Variable-2*

| timestamp | 값 |
| --------- | ----- |
| 12:00:00  | 2.2   |
| 12:00:30  | 2.6   |
| 12:01:00  | 1.4   |
| 12:01:30  | 1.7   |
| 12:02:00  | 2.0   |

이제 병합된 테이블이 더 적절합니다.

| timestamp | Variable-1 | Variable-2 |
| --------- | -------- | -------- |
| 12:00:00  | 1.0      | 2.2      |
| 12:00:30  | 1.5      | 2.6      |
| 12:01:00  | 0.9      | 1.4      |
| 12:01:30  | 2.2      | 1.7      |
| 12:02:00  | 1.3      | 2.0      |

가까운 타임스탬프의 서로 다른 변수 값이 잘 정렬되며 이제 MVAD 모델이 상관 관계 정보를 추출할 수 있습니다.

## <a name="common-pitfalls"></a>공통 문제

[오류 코드 테이블](./troubleshoot.md) 외에도 고객으로부터 MVAD API를 사용하는 동안 몇 가지 공통 문제를 알아보았습니다. 이 테이블은 해당 문제를 방지하는 데 도움이 됩니다.

| 문제 | 결과 |설명 및 해결 방법 |
| --------- | ----- | ----- |
| 학습 데이터 및/또는 유추 데이터의 타임스탬프가 각 변수의 개별 데이터 빈도에 맞게 반올림되지 않았습니다. | 유추 결과의 타임스탬프가 예상과 달리 타임스탬프가 너무 적거나 너무 많습니다.  | [타임스탬프 반올림](#timestamp-round-up)을 참조하세요.  |
| 학습 데이터에 변칙 데이터 포인트가 너무 많음 | 모델 정확도는 학습 중 변칙 데이터 포인트를 일반 패턴으로 처리하기 때문에 부정적인 영향을 받습니다. | 경험적으로 비정상 비율을 **1%** 이하로 유지하면 도움이 됩니다. |
| 학습 데이터가 너무 적음 | 모델 정확도가 손상되었습니다. | 경험적으로 양호한 정확도를 유지하기 위해 MVAD 모델을 학습시키는 데는 변수당 15,000개 이상의 데이터 포인트(타임스탬프)가 필요합니다.|
| `isAnomaly`=`true`가 있는 모든 데이터 포인트를 변칙으로 간주 | 가양성이 너무 많음 | `isAnomaly` 및 `severity`(또는 `score`)를 둘 다 사용하여 심각하지 않은 변칙을 선별하고 선택적으로 그룹화를 통해 변칙 기간을 확인하여 임의 노이즈를 억제해야 합니다. `severity`와 `score` 간 차이점은 아래 [FAQ](#faq) 섹션을 참조하세요.  |
| 하위 폴더는 학습 또는 유추를 위해 데이터 파일로 압축됩니다. | 하위 폴더 내의 csv 데이터 파일은 학습 및/또는 유추 중에 무시됩니다. | Zip 파일에는 하위 폴더가 허용되지 않습니다. 자세한 내용은 [폴더 구조](#folder-structure)를 참조하세요. |
| 유추 데이터 파일에 데이터가 너무 많음: 예를 들어, 유추 데이터 zip 파일에서 모든 기록 데이터 압축 | 오류가 표시되지 않을 수 있지만, 유추를 실행하려는 경우뿐 아니라 Azure Blob에 zip 파일을 업로드하려는 경우 성능이 저하됩니다. | 자세한 내용은 [데이터 수량](#data-quantity)을 참조하세요. |
| 아직 MVAD를 지원하지 않는 Azure 지역에서 Anomaly Detector 리소스를 만들고 MVAD API 호출  | MVAD API를 호출하는 동안 “리소스를 찾을 수 없음” 오류가 표시됩니다. | 미리 보기 단계 중에는 MVAD를 제한된 지역에서만 사용할 수 있습니다. MVAD 지역 롤아웃에 대해 최신 상태를 유지하려면 [Anomaly Detector의 새로운 기능](../whats-new.md)에 책갈피를 설정하세요. GitHub 문제를 제출하거나 AnomalyDetector@microsoft.com으로 연락하여 특정 지역을 요청할 수도 있습니다. |

## <a name="faq"></a>FAQ

### <a name="how-does-mvad-sliding-window-work"></a>MVAD 슬라이딩 윈도우는 어떻게 작동하나요?

두 가지 예제를 사용하여 MVAD의 슬라이딩 윈도우 작동 방식을 알아보겠습니다. `slidingWindow` = 1,440을 설정하고 입력 데이터가 1분 단위로 세분화된다고 가정합니다.

* **스트리밍 시나리오**: “2021-01-02T00:00:00Z”에서 하나의 데이터 포인트가 변칙인지 여부를 예측하려고 합니다. `startTime` 및 `endTime`은 동일한 값(“2021-01-02T00:00:00Z”)입니다. 그러나 유추 데이터 원본에는 최소 1,440 + 1개의 타임스탬프가 포함되어야 합니다. 이 때문에, MVAD는 대상 데이터 포인트(“2021-01-02T00:00:00Z”) 이전 선행 데이터를 사용하여 대상이 변칙인지 여부를 결정합니다. 이 경우 필요한 선행 데이터의 길이는 `slidingWindow` 또는 1,440입니다. 1,440 = 60 * 24이므로 입력 데이터는 최신 “2021-01-01T00:00:00Z”에서 시작해야 합니다.

* **일괄 처리 시나리오**: 예측할 대상 데이터 포인트가 여러 개 있습니다. `endTime`은 `startTime`보다 큽니다. 이 시나리오의 유추는 “이동 창” 방식으로 수행됩니다. 예를 들어, MVAD는 `2021-01-01T00:00:00Z`~`2021-01-01T23:59:00Z`(포함) 사이 데이터를 사용하여 `2021-01-02T00:00:00Z`의 데이터가 변칙인지 여부를 확인합니다. 그런 다음, 앞으로 이동하고 `2021-01-01T00:01:00Z`~`2021-01-02T00:00:00Z`(포함) 사이 데이터를 사용하여 `2021-01-02T00:01:00Z`의 데이터가 변칙인지 여부를 확인합니다. `endTime`에 지정된 마지막 타임스탬프(또는 실제 최신 타임스탬프)까지 동일한 방식으로(비교에 1,440개 데이터 포인트 사용) 계속 이동합니다. 따라서 유추 데이터 원본에는 `startTime` - `slidingWindow` 사이 데이터가 포함되어야 하며 이상적으로는 `slidingWindow` + (`endTime` - `startTime`)의 총 크기가 포함됩니다.

### <a name="why-only-accepting-zip-files-for-training-and-inference"></a>학습과 유추를 위해 zip 파일만 허용하는 이유는 무엇인가요?

일괄 처리 시나리오에서는 학습 및 유추 데이터의 크기가 매우 커서 HTTP 요청 본문에 넣을 수 없을 것으로 예상하기 때문에 zip 파일을 사용합니다. 이를 통해 사용자는 모델 유효성 검사 또는 데이터 분석을 위해 기록 데이터에서 일괄 처리 유추를 수행할 수 있습니다.

그러나 이 방법은 스트리밍 유추와 빈도가 높은 데이터에서는 다소 불편할 수 있습니다. 사용자가 요청 본문의 데이터를 전달할 수 있는 스트리밍 유추를 위해 특별히 디자인된 새 API를 추가할 계획이 있습니다.

### <a name="whats-the-difference-between-severity-and-score"></a>`severity`와 `score`의 차이는 무엇인가요?

일반적으로 `severity`를 필터로 사용하여 비즈니스에 중요하지 않은 ‘변칙’을 선별하는 것이 좋습니다. 시나리오와 데이터 패턴에 따라 덜 중요한 변칙은 종종 비교적 더 낮은 `severity` 값이나 무작위 급증과 같은 독립적인(불연속) 높은 `severity` 값을 가집니다.

연속적인 높은 `severity` 값의 기간 또는 `severity`에 대해 임계값보다 더 정교한 규칙이 필요한 경우 `score`를 사용하여 더 강력한 필터를 빌드하는 것이 좋습니다. MVAD가 `score`를 사용하여 변칙을 확인하는 방법을 이해하면 도움이 될 수 있습니다.

데이터 포인트가 전역 및 로컬 관점에서 변칙인지 여부를 고려합니다. 타임스탬프의 `score`가 특정 임계값보다 높으면 타임스탬프는 변칙으로 표시됩니다. `score`가 임계값보다 낮지만 세그먼트에서 비교적 더 높은 경우에도 변칙으로 표시됩니다.

## <a name="next-steps"></a>다음 단계

* [빠른 시작: Anomaly Detector 다변량 클라이언트 라이브러리 사용](../quickstarts/client-libraries-multivariate.md).
* [Anomaly Detector 다변량을 지원하는 기본 알고리즘에 관해 알아보기](https://arxiv.org/abs/2009.02040)
