---
title: '선형 회귀: 구성 요소 참조'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning 선형 회귀 구성 요소를 사용하여 파이프라인에서 사용할 선형 회귀 모델을 만드는 방법을 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 04/22/2020
ms.openlocfilehash: 4bf857ad0cd7dc458f1273d061e30b4370bf8313
ms.sourcegitcommit: e41827d894a4aa12cbff62c51393dfc236297e10
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/04/2021
ms.locfileid: "131570133"
---
# <a name="linear-regression-component"></a>선형 회귀 구성 요소
이 문서에서는 Azure Machine Learning 디자이너의 구성 요소에 대해 설명합니다.

이 구성 요소를 사용하여 파이프라인에서 사용할 선형 회귀 모델을 만듭니다.  선형 회귀는 하나 이상의 독립 변수와 숫자 결과 또는 종속 변수 간의 선형 관계를 설정하려고 합니다. 

이 구성 요소를 사용하여 선형 회귀 메서드를 정의한 다음 레이블이 지정된 데이터 세트를 사용하여 모델을 학습합니다. 그러면 학습된 모델을 예측에 사용할 수 있습니다.

## <a name="about-linear-regression"></a>선형 회귀 정보

선형 회귀는 일반적인 통계 방법으로, 기계 학습에서 채택되었으며 선에 맞추고 오차를 측정하기 위한 여러 가지 새로운 방법으로 향상되었습니다. 간단히 말해서, 회귀란 숫자 대상의 예측을 말합니다. 선형 회귀는 기본 예측 작업을 위한 간단한 모델을 원하는 경우에 적합합니다. 뿐만 아니라, 선형 회귀는 복잡하지 않은 고차원 스파스 데이터 세트에도 효율적입니다.

Azure Machine Learning은 선형 회귀 외에도 다양한 회귀 모델을 지원합니다. 그러나 “회귀”라는 용어는 느슨하게 해석될 수 있으며 다른 도구에서 제공하는 일부 회귀 분석은 지원되지 않습니다.

+ 클래식 회귀 문제에는 단일 독립 변수와 종속 변수가 포함됩니다. 이를 ‘단순 회귀’라고 합니다.  이 구성 요소는 간단한 회귀를 지원합니다.

+ ‘다중 선형 회귀’에는 단일 종속 변수에 영향을 주는 둘 이상의 독립 변수가 포함됩니다. 여러 입력을 사용하여 단일 숫자 결과를 예측하는 문제를 ‘다변량 선형 회귀’라고도 합니다.

    **선형 회귀** 구성 요소는 대부분의 다른 회귀 구성 요소와 마찬가지로 이러한 문제를 해결할 수 있습니다.

+ ‘다중 레이블 회귀’는 단일 모델 내에서 여러 종속 변수를 예측하는 작업입니다. 예를 들어, 다중 레이블 로지스틱 회귀에서 샘플은 여러 다른 레이블에 할당될 수 있습니다. 단일 클래스 변수 내에서 여러 수준을 예측하는 작업과는 다릅니다.

    이 회귀 분석은 Azure Machine Learning에서 지원되지 않습니다. 여러 변수를 예측하려면 예측할 각 출력에 대한 학습자를 별도로 만듭니다.

수년간 통계학자들은 점점 더 발전된 회귀 방법을 개발해 오고 있습니다. 선형 회귀의 경우도 마찬가지입니다. 이 구성 요소는 오류를 측정하고 회귀선을 맞추는 두 가지 메서드인 최소 제곱 메서드와 기울기 하강을 지원합니다.

- **경사하강법** 은 모델 학습 프로세스의 각 단계에서 오차의 양을 최소화하는 방법입니다. 기울기 하강에는 여러 변형이 있으며, 다양한 학습 문제에 맞게 최적화하기 위해 광범위하게 연구되었습니다. **솔루션 방법** 에서 이 옵션을 선택하는 경우 다양한 매개 변수를 설정하여 단계 크기, 학습 속도 등을 제어할 수 있습니다. 이 옵션은 통합 매개 변수 스윕 사용도 지원합니다.

- **최소자승법** 은 선형 회귀 분석에서 가장 일반적으로 사용되는 기법 중 하나입니다. 예를 들어 최소자승법은 Microsoft Excel용 분석 도구에서 사용되는 방법입니다.

    최소자승법은 실제 값에서 예측선까지 거리의 제곱 합으로 오류를 계산하고 제곱 오차를 최소화하여 모델을 적합하게 하는 손실 함수를 나타냅니다. 이 방법은 입력과 종속 변수 간에 강력한 선형 관계가 있다고 가정합니다.

## <a name="configure-linear-regression"></a>선형 회귀 구성

이 구성 요소는 다른 옵션을 통해 회귀 모델을 맞추기 위한 두 가지 방법을 지원합니다.

+ [최소자승법을 사용하여 회귀 모델에 맞춤](#create-a-regression-model-using-ordinary-least-squares)

    작은 데이터 세트의 경우 최소자승법을 선택하는 것이 가장 좋습니다. 그러면 Excel과 비슷한 결과가 제공됩니다.
    
+ [온라인 경사하강법을 사용하여 회귀 모델 만들기](#create-a-regression-model-using-online-gradient-descent)

    기울기 하강은 더욱 복잡하며 변수의 수에 비해 학습 데이터가 너무 적은 모델에 더욱 적합한 손실 함수입니다.

### <a name="create-a-regression-model-using-ordinary-least-squares"></a>최소자승법을 사용하여 회귀 모델 만들기

1. 디자이너에서 **파이프라인에 선형 회귀 모델** 구성 요소를 추가합니다.

    이 구성 요소는 **Machine Learning** 범주에서 찾을 수 있습니다. **모델 초기화를** 확장하고 **회귀** 를 확장한 다음 **선형 회귀 모델** 구성 요소를 파이프라인으로 끕니다.

2. **속성** 창의 **솔루션 방법** 드롭다운 목록에서 **최소자승법** 을 선택합니다. 이 옵션은 회귀선을 찾는 데 사용되는 계산 방법을 지정합니다.

3. **L2 정규화 가중치** 에서 L2 정규화의 가중치로 사용할 값을 입력합니다. 과잉 맞춤을 방지하려면 0이 아닌 값을 사용하는 것이 좋습니다.

     정규화가 모델 맞춤에 미치는 영향에 대한 자세한 내용은 [Machine Learning의 L1 및 L2 정규화](/archive/msdn-magazine/2015/february/test-run-l1-and-l2-regularization-for-machine-learning) 문서를 참조하세요.

4. 절편항을 보려면 **절편항 포함** 옵션을 선택합니다.

    회귀 수식을 검토할 필요가 없는 경우에는 이 옵션의 선택을 취소합니다.

5. 필요에 따라 **난수 시드** 에 모델에서 사용되는 난수 생성기를 시드할 값을 입력합니다.

    동일한 파이프라인을 여러 번 실행할 때 결과를 동일하게 유지하려는 경우 시드 값을 사용하면 유용합니다. 그러지 않으면 기본값은 시스템 클록의 값을 사용하는 것입니다.


7. 모델 [학습](./train-model.md) 구성 요소를 파이프라인에 추가하고 레이블이 있는 데이터 세트를 연결합니다.

8. 파이프라인을 제출합니다.

### <a name="results-for-ordinary-least-squares-model"></a>최소자승법 모델의 결과

학습 완료 후:


+ 예측을 만들려면 학습된 모델을 새 값의 데이터 세트와 함께 [모델 점수 매기기](./score-model.md) 구성 요소에 연결합니다. 


### <a name="create-a-regression-model-using-online-gradient-descent"></a>온라인 경사하강법을 사용하여 회귀 모델 만들기

1. 디자이너에서 **파이프라인에 선형 회귀 모델** 구성 요소를 추가합니다.

    이 구성 요소는 **Machine Learning** 범주에서 찾을 수 있습니다. **모델 초기화를** 확장하고 **회귀를** 확장한 다음 **선형 회귀 모델** 구성 요소를 파이프라인으로 끕니다.

2. **속성** 창의 **솔루션 방법** 드롭다운 목록에서 회귀선을 찾는 데 사용되는 계산 방법으로 **온라인 경사하강법** 을 선택합니다.

3. **트레이너 모드 만들기** 에서 미리 정의된 매개 변수 세트를 사용하여 모델을 학습할지 또는 매개 변수 스윕을 사용하여 모델을 최적화할지 여부를 지정합니다.

    + **단일 매개 변수**: 선형 회귀 네트워크 구성 방법을 알고 있는 경우 특정 값 세트를 인수로 제공할 수 있습니다.
    
    + **매개 변수 범위**: 최적 매개 변수를 잘 모르는 상태에서 매개 변수 스윕을 실행하려면 이 옵션을 선택합니다. 반복할 값의 범위를 선택하면 [모델 하이퍼 매개 변수 튜닝](tune-model-hyperparameters.md)이 제공된 설정의 가능한 모든 조합을 반복하여 최적 결과를 생성하는 하이퍼 매개 변수를 확인합니다.  

   
4. **학습 속도** 에서 확률적 경사하강법 최적화 프로그램의 초기 학습 속도를 지정합니다.

5. **학습 epoch 수** 에서 알고리즘이 예제를 반복해야 하는 횟수를 나타내는 값을 입력합니다. 예제 수가 적은 데이터 집합의 경우 이 횟수는 수렴에 도달할 정도로 커야 합니다.

6. **기능 정규화**: 모델을 학습하는 데 사용되는 숫자 데이터를 이미 정규화한 경우에는 이 옵션의 선택을 취소할 수 있습니다. 기본적으로 구성 요소는 모든 숫자 입력을 0에서 1 사이의 범위로 정규화합니다.

    > [!NOTE]
    > 
    > 채점에 사용되는 새 데이터에 동일한 정규화 방법을 적용해야 합니다.

7. **L2 정규화 가중치** 에서 L2 정규화의 가중치로 사용할 값을 입력합니다. 과잉 맞춤을 방지하려면 0이 아닌 값을 사용하는 것이 좋습니다.

    정규화가 모델 맞춤에 미치는 영향에 대한 자세한 내용은 [Machine Learning의 L1 및 L2 정규화](/archive/msdn-magazine/2015/february/test-run-l1-and-l2-regularization-for-machine-learning) 문서를 참조하세요.


9. 반복이 진행됨에 따라 학습 속도를 줄이려면 **학습 속도 감소** 옵션을 선택합니다.  

10. 필요에 따라 **난수 시드** 에 모델에서 사용되는 난수 생성기를 시드할 값을 입력합니다. 동일한 파이프라인을 여러 번 실행할 때 결과를 동일하게 유지하려는 경우 시드 값을 사용하면 유용합니다.


12. 모델을 학습시킵니다.

    + **트레이너 만들기 모드를** **단일 매개 변수로** 설정하면 태그가 지정된 데이터 세트와 [모델 학습](train-model.md) 구성 요소를 연결합니다.  
  
    + **트레이너 모드 만들기** 를 **매개 변수 범위** 로 설정하는 경우 태그가 지정된 데이터 세트를 연결하고 [모델 하이퍼 매개 변수 조정](tune-model-hyperparameters.md)을 사용하여 모델을 학습시킵니다.  
  
    > [!NOTE]
    > 
    > [모델 학습](train-model.md)에 매개 변수 범위를 전달하는 경우 단일 매개 변수 목록의 기본값만 사용합니다.  
    > 
    > 단일 매개 변수 값 집합을 [모델 튜닝 하이퍼 매개](tune-model-hyperparameters.md) 변수 구성 요소에 전달하는 경우 각 매개 변수에 대한 설정 범위가 예상되는 경우 값을 무시하고 학습자의 기본값을 사용합니다.  
    > 
    > **매개 변수 범위** 옵션을 선택하고 매개 변수에 단일 값을 입력하는 경우 다른 매개 변수가 값 범위에서 변경되더라도 지정한 단일 값은 스윕 전체에서 사용됩니다.

13. 파이프라인을 제출합니다.

### <a name="results-for-online-gradient-descent"></a>온라인 경사하강법의 결과

학습 완료 후:

+ 예측을 만들려면 학습된 모델을 새 입력 데이터와 함께 [모델 점수 매기기](./score-model.md) 구성 요소에 연결합니다.


## <a name="next-steps"></a>다음 단계

Azure Machine Learning [사용할 수 있는 구성 요소 집합을](component-reference.md) 참조하세요.