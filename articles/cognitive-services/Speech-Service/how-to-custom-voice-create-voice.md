---
title: Custom Voice 만들기 - Speech Service
titleSuffix: Azure Cognitive Services
description: 데이터를 업로드할 준비가 되면 Custom Voice 포털로 이동합니다. Custom Voice 프로젝트를 만들거나 선택합니다. 프로젝트는 음성 학습에 사용할 데이터로 올바른 언어/로캘 및 성별 속성을 공유해야 합니다.
services: cognitive-services
author: eric-urban
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: eur
ms.openlocfilehash: 16f9d66b669e792d0bccc2676bdc1db327de3229
ms.sourcegitcommit: 2cc9695ae394adae60161bc0e6e0e166440a0730
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/03/2021
ms.locfileid: "131507211"
---
# <a name="create-and-use-your-voice-model"></a>음성 모델 만들기 및 사용

[학습 데이터 준비](how-to-custom-voice-prepare-data.md)에서 사용자 지정 신경망 음성 및 다양한 형식 요구 사항을 학습하는 데 사용할 수 있는 다양한 데이터 형식에 대해 배웠습니다. 데이터와 성우의 성우 구술문을 준비한 후에는 [Speech Studio](https://aka.ms/custom-voice-portal)로 업로드를 시작할 수 있습니다. 이 문서에서는 Speech Studio 포털을 통해 사용자 지정 신경망 음성 학습하는 방법을 알아봅니다. 사용자 지정 신경망 음성에 대해 [지원되는 언어](language-support.md#customization)를 참조하세요.

## <a name="prerequisites"></a>사전 요구 사항

* [사용자 지정 신경망 음성 시작](how-to-custom-voice.md) 완료
* [학습 데이터 준비](how-to-custom-voice-prepare-data.md)

## <a name="set-up-voice-talent"></a>성우 설정

성우란 신경망 음성 모델을 만들기 위해 음성을 녹음하는 개인 또는 대상 화자입니다. 음성을 만들기 전에 음성 가상 사용자를 정의하고 적절한 성우를 선정합니다. 음성 샘플 녹음에 대한 자세한 내용은 [자습서](record-custom-voice-samples.md)를 참조하세요.

신경망 음성을 학습하려면 자신의 음성 데이터를 사용하여 사용자 지정 음성 모델을 학습시키는 데 동의한 성우가 녹음한 오디오 파일이 있는 성우 프로필을 만들어야 합니다. 녹음 스크립트를 준비할 때 다음과 같은 문장을 포함해야 합니다.

**"나[성 및 이름]는 내 음성의 합성 버전을 만들고 사용하기 위해 [회사 이름]에서 내 음성 녹음이 사용된다는 것을 알고 있습니다."**
이 문장은 학습 데이터가 동의문의 오디오와 일치하는지 확인하는 데 사용됩니다. > 여기에서 [성우 확인](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)에 대해 자세히 알아보세요.

> [!NOTE]
> 사용자 지정 신경망은 제한된 액세스로 사용할 수 있습니다. [책임 있는 AI 요구 사항](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)을 이해한 다음, [액세스 권한을 적용](https://aka.ms/customneural)해야 합니다. 

다음 단계에서는 성우의 성우 언어 동의 파일을 준비했다고 가정합니다.  [Speech Studio](https://aka.ms/custom-voice-portal)로 이동하여 사용자 지정 신경망 음성 프로젝트를 선택한 다음, 다음 단계에 따라 성우 프로필을 만듭니다.

1. **텍스트 음성 변환** > **사용자 지정 음성** > **프로젝트 선택** > **성우 설정** 을 진행합니다.

2. **성우 추가** 를 선택합니다.

3. 다음으로, 음성 특성을 정의하려면 사용할 **대상 시나리오** 를 선택합니다. 그런 다음, **음성 특성** 을 설명합니다.

> [!NOTE]
> 제공하는 시나리오는 애플리케이션 양식에 신청한 내용과 일관되어야 합니다.

4. 그런 다음, **성우 문 업로드** 로 이동하여 지침에 따라 미리 준비한 성우 문을 업로드합니다.

> [!NOTE]
> 녹음 환경 및 말하기 스타일을 비롯하여 구술문이 학습 데이터와 동일한 설정으로 녹음되도록 해야 합니다.

5. 마지막으로 **검토 및 만들기** 로 이동하여 설정을 검토하고 **제출** 을 선택할 수 있습니다.

## <a name="upload-your-data"></a>데이터 업로드

데이터를 업로드할 준비가 되면 **학습 데이터 준비** 탭으로 이동하여 첫 번째 학습 세트를 추가하고 데이터를 업로드합니다.  학습 세트는 음성 모델 학습에 사용되는 오디오 발화 및 해당 매핑 스크립트의 세트입니다. 학습 세트를 사용하여 학습 데이터를 구성할 수 있습니다. 데이터 준비 상태 검사는 각 학습 세트별로 수행됩니다. 여러 데이터를 학습 세트로 가져올 수 있습니다.

다음을 수행하여 학습 데이터를 만들고 검토할 수 있습니다.

1. **학습 데이터 준비** 탭에서 **학습 세트 추가** 를 선택하여 **이름** 및 **설명** > **만들기** 를 입력하여 새 학습 세트를 추가합니다.

   학습 세트가 성공적으로 만들어지면 데이터 업로드를 시작할 수 있습니다. 

2. 데이터를 업로드하려면 **데이터 업로드** > **데이터 형식 선택** > **데이터 업로드** 를 선택하고 **대상 학습 세트를 지정하고** > 데이터에 대한 **이름** 및 **설명** 을 입력한 다음 > 설정을 검토하고 **제출** 을 선택합니다.

> [!NOTE]
>- 중복된 오디오 이름은 학습에서 제거됩니다. 선택한 데이터에 한 개 또는 여러 .zip 파일에 동일한 오디오 이름이 포함되지 않도록 해야 합니다. 발화 ID(오디오 또는 스크립트 파일)가 중복되는 경우 거부됩니다.
>- 이전 버전의 Speech Studio에서 데이터 파일을 만든 경우 데이터에 대한 학습 세트를 미리 지정해야 사용할 수 있습니다. 그렇지 않으면 느낌표가 데이터 이름에 추가되고 데이터를 사용할 수 없게 됩니다.

업로드하는 각 데이터는 선택한 데이터 형식에 대한 요구 사항을 충족해야 합니다. 사용자 지정 신경망 음성 서비스에서 데이터를 정확하게 처리하도록 업로드하기 전에 데이터의 형식을 올바르게 지정하는 것이 중요합니다. [학습 데이터 준비](how-to-custom-voice-prepare-data.md)로 이동하여 데이터 형식이 올바른지 확인합니다.

> [!NOTE]
> - 표준 구독(S0) 사용자는 다섯 개의 데이터 파일을 동시에 업로드할 수 있습니다. 업로드 개수가 초과되면 적어도 한 개의 데이터 파일에 대한 가져오기가 완료될 때까지 기다립니다. 그런 다음, 다시 시도하세요.
> - 구독당 가져올 수 있는 최대 데이터 파일 수는 무료 구독(F0) 사용자의 경우 10개의 .zip 파일이고 표준 구독(S0) 사용자의 경우 500개입니다.

**제출** 단추를 누르면 데이터 파일이 자동으로 검증됩니다. 데이터 유효성 검사에는 오디오 파일의 파일 형식, 크기 및 샘플링 레이트를 확인하는 일련의 검사가 포함됩니다. 오류가 있으면 이를 수정하고 다시 제출합니다. 

데이터가 업로드되면 학습 세트 세부 정보 보기에서 세부 정보를 확인할 수 있습니다. **개요** 탭에서 각 데이터의 발음 점수와 잡음 수준을 추가로 확인할 수 있습니다. 발음 점수의 범위는 0에서 100까지입니다. 일반적으로 70점 아래의 점수는 음성 오류 또는 스크립트 불일치를 나타냅니다. 악센트가 강하면 발음 점수를 떨어뜨리고 생성된 디지털 음성에 영향을 줄 수 있습니다.

SNR(신호 대 잡음 비율)이 더 높을 수록 오디오의 잡음이 더 낮은 것입니다. 일반적으로 전문 스튜디오에서 녹음하면 50 이상의 SNR에 도달할 수 있습니다. SNR이 20보다 낮은 오디오는 생성된 음성에서 잡음이 뚜렷하게 들릴 수 있습니다.

발음 점수가 낮거나 신호 대 잡음 비율이 떨어지는 모든 발화는 다시 녹음하는 것이 좋습니다. 다시 녹음할 수 없다면 해당 발화를 데이터에서 제외할 수 있습니다.

**데이터 세부 정보** 에서 학습 세트의 데이터 세부 정보를 확인할 수 있습니다. 데이터에 대한 일반적인 문제가 있는 경우 표시된 메시지의 지침에 따라 학습 전에 수정합니다.

문제는 세 가지 유형으로 나뉩니다. 다음 세 개의 표를 참조하여 각 오류 유형을 확인합니다.

아래 표에 나열된 첫 번째 유형의 오류를 수동으로 수정합니다. 그렇지 않으면 이러한 오류가 있는 데이터는 학습 중에 제외됩니다.

| 범주 | 이름 | 설명 |
| --------- | ----------- | --------------------------- |
| 스크립트 | 잘못된 구분 기호| 발화 ID와 스크립트 내용을 TAB 문자로 구분해야 합니다.|
| 스크립트 | 잘못된 스크립트 ID| 스크립트 줄 ID는 숫자여야 합니다.|
| 스크립트 | 복제된 스크립트|스크립트 내용의 각 줄은 고유해야 합니다. 줄은 {}와 중복됩니다.|
| 스크립트 | 스크립트가 너무 깁니다.| 이 스크립트는 1,000자 미만이어야 합니다.|
| 스크립트 | 일치하는 오디오가 없습니다.| 각 발화의 ID(스크립트 파일의 각 줄)는 오디오 ID와 일치해야 합니다.|
| 스크립트 | 유효한 스크립트 없음| 이 데이터 세트에서 유효한 스크립트를 찾을 수 없습니다. 세부 문제 목록에 나타나는 스크립트 줄을 수정합니다.|
| 오디오 | 일치하는 스크립트가 없습니다.| 스크립트 ID와 일치하는 오디오 파일이 없습니다. wav 파일의 이름은 스크립트 파일의 ID와 일치해야 합니다.|
| 오디오 | 잘못된 오디오 형식| .wav 파일의 오디오 형식이 잘못되었습니다. [SoX](http://sox.sourceforge.net/)와 같은 오디오 도구를 사용하여 wav 파일 형식을 확인합니다.|
| 오디오 | 낮은 샘플링 레이트| .wav 파일의 샘플링 속도는 16KHz보다 낮을 수 없습니다.|
| 오디오 | 너무 긴 오디오| 오디오 시간이 30초보다 깁니다. 긴 오디오를 여러 파일로 나눕니다. 발화는 15초 미만이어야 합니다.|
| 오디오 | 유효한 오디오 없음| 이 데이터 세트에서 유효한 오디오를 찾을 수 없습니다. 오디오 데이터를 확인하고 다시 업로드하세요.|

아래 표에 나열된 두 번째 유형의 오류는 자동으로 수정되지만 고정된 데이터를 다시 확인하는 것이 좋습니다.

| 범주 | 이름 | 설명 |
| --------- | ----------- | --------------------------- |
| 오디오 | 스테레오 오디오 자동 고정 | 오디오 샘플 녹음/녹화에 모노를 사용합니다. 스테레오 오디오 채널은 자동으로 모노 채널로 병합되어 콘텐츠가 손실될 수 있습니다.  정규화된 데이터 세트를 다운로드하고 검토합니다.|
| 볼륨 | 볼륨 피크 자동 고정 |볼륨 피크는 -3dB(최대 볼륨의 70%)에서 -6dB(50%) 범위 내에 있어야 합니다. 샘플 녹음/녹화 또는 데이터 준비 중에 볼륨 피크를 제어합니다. 이 오디오는 자동으로 피크 범위에 맞게 선형으로 조정됩니다(-4dB 또는 65%). 정규화된 데이터 세트를 다운로드하고 검토합니다.|
|불일치 | 무음 자동 수정| 시작 무음은 200ms보다 긴 것으로 감지되었으며 자동으로 200ms로 잘립니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 |무음 자동 수정 | 끝 무음은 200ms보다 긴 것으로 감지되었으며 자동으로 200ms로 잘립니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 |무음 자동 수정 |시작 무음은 100ms보다 짧은 것으로 감지되었으며 자동으로 100ms로 확장되었습니다. 정규화된 데이터 세트를 다운로드하고 검토합니다. |
| 불일치 |무음 자동 수정 | 마지막 무음은 100ms보다 짧은 것으로 감지되었으며 자동으로 100ms로 확장되었습니다. 정규화된 데이터 세트를 다운로드하고 검토합니다.|

아래 표에 나열된 세 번째 오류 유형이 수정되지 않은 경우 이러한 오류가 있는 데이터는 학습 중에 제외되지는 않지만 학습 품질에 영향을 미칩니다. 고품질 학습의 경우 이러한 오류를 수동으로 수정하는 것이 좋습니다. 

| 범주 | 이름 | 설명 |
| --------- | ----------- | --------------------------- |
| 스크립트 | 정규화되지 않은 텍스트|이 스크립트는 숫자 0-9를 포함합니다. 정규화된 단어로 확장하고 오디오와 일치시킵니다. 예를 들어 ‘123’을 ‘백이십삼’으로 정규화합니다.|
| 스크립트 | 정규화되지 않은 텍스트|이 스크립트에는 {} 기호가 포함되어 있습니다. 오디오와 일치하도록 기호를 정규화합니다. 예: '50%'에서 '50퍼센트'로.|
| 스크립트 | 질문 발화 부족| 전체 발화의 최소 10%는 질문 문장이어야 합니다. 이는 음성 모델이 질문 톤을 적절하게 표현하는 데 도움이 됩니다.|
| 스크립트 |감탄문 발화 부족| 전체 발화의 10% 이상이 감탄문이어야 합니다. 이는 음성 모델이 흥분된 톤을 적절하게 표현하는 데 도움이 됩니다.|
| 오디오| 신경망 음성에 대해 샘플링 레이트가 낮음 | 신경망 음성을 만들려면 .wav 파일의 샘플링 속도를 24KHz 이상으로 하는 것이 좋습니다. 24KHz가 더 낮으면 자동으로 업샘플링됩니다.|
| 볼륨 |전체 볼륨이 너무 낮음|볼륨은 -18dB(최대 볼륨의 10%)보다 낮아서는 안 됩니다. 샘플 녹음/녹화 또는 데이터 준비 중에 적절한 범위 내에서 볼륨 평균 수준을 제어합니다.|
| 볼륨 | 볼륨 오버플로| {}에서 오버플로 볼륨이 감지되었습니다. 피크 값에서 볼륨 오버플로를 방지하기 위해 녹음/녹화 장비를 조정합니다.|
| 볼륨 | 무음 문제 시작 | 처음 100ms 무음이 깨끗하지 않습니다. 녹음/녹화 노이즈 플로어 수준을 줄이고 시작 시 처음 100ms를 무음으로 둡니다.|
| 볼륨| 무음 문제 종료| 마지막 100ms 무음이 깨끗하지 않습니다.  녹음/녹화 노이즈 플로어 수준을 줄이고 마지막 100ms를 무음으로 둡니다.|
| 불일치 | 점수가 낮은 단어|스크립트와 오디오 콘텐츠를 검토하여 이러한 항목이 일치하는지 확인하고 잡음층 수준을 제어합니다. 긴 침묵의 길이를 줄이거나 오디오가 너무 길면 여러 발화로 나눕니다.|
| 불일치 | 무음 문제 시작 |첫 단어가 나오기 전에 추가 오디오가 들렸습니다. 스크립트와 오디오 콘텐츠를 검토하여 일치하는지 확인하고, 노이즈 층 수준을 제어하고, 처음 100ms를 무음으로 만듭니다.|
| 불일치 | 무음 문제 종료| 마지막 단어 뒤에 추가 오디오가 들렸습니다. 스크립트와 오디오 콘텐츠를 검토하여 일치하는지 확인하고 노이즈 층 수준을 제어하며 마지막 100ms를 무음으로 만듭니다.|
| 불일치 | 낮은 신호 대 잡음 비율 | 오디오 SNR 수준이 20dB보다 낮습니다. 최소 35dB가 권장됩니다.|
| 불일치 | 사용 가능한 점수가 없습니다. |이 오디오의 음성 콘텐츠를 인식하지 못했습니다. 오디오 및 스크립트 내용을 확인하여 오디오가 유효하고 스크립트와 일치하는지 확인합니다.|

## <a name="train-your-custom-neural-voice-model"></a>사용자 지정 신경망 음성 모델 학습

데이터 파일이 검증된 후 이를 사용하여 사용자 지정 신경망 음성 모델을 구축할 수 있습니다.

1. 모델 **학습** 탭에서 **모델 학습을** 선택하여 업로드한 데이터를 사용하여 음성 모델을 만듭니다.

2. 모델 및 대상 언어에 사용할 신경망 학습 방법을 선택합니다.

기본적으로 음성 모델은 학습 데이터와 동일한 언어로 학습됩니다. 음성 모델에 대한 보조 언어(미리 보기)를 만들도록 선택할 수도 있습니다.  사용자 지정 신경망 음성 및 교차 다국어 기능에 대해 지원되는 언어를 확인하세요([사용자 지정을 위한 언어](language-support.md#customization)).

사용자 지정 신경망 음성의 학습은 무료가 아닙니다. 자세한 내용은 [가격 책정을](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/) 확인하세요. 그러나 S0 Speech 리소스를 사용하여 2021년 3월 31일 이전에 배포된 통계 매개변수 또는 연결 음성 모델이 있는 경우 Azure 구독에 무료 신경 학습 크레딧이 제공되며, 5가지 버전의 신경망 음성을 무료로 학습할 수 있습니다.

3. 다음으로, 학습에 사용할 데이터를 선택하고 화자 파일을 지정합니다.

>[!NOTE]
>- 사용자 지정 신경망 음성을 만들려면 최소 300개의 발화를 선택해야 합니다.
>- 신경망 음성을 학습하려면 자신의 음성 데이터를 사용자 지정 음성 모델을 학습시키는 데 사용할 것을 승인한 성우가 제공한 오디오 동의 파일을 포함한 성우 프로필을 지정해야 합니다. 사용자 지정 신경망은 제한된 액세스로 사용할 수 있습니다. [책임 있는 AI 요구 사항](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)을 이해하고 [여기에서 액세스 권한을 적용](https://aka.ms/customneural)합니다.

4. 그런 다음, 테스트 스크립트를 선택합니다.

각 학습은 기본 스크립트를 사용하여 모델을 테스트하는 데 도움이 되는 100개의 샘플 오디오 파일을 자동으로 생성합니다. 사용자 고유의 테스트 스크립트를 선택 사항으로 제공할 수도 있습니다. 테스트 스크립트는 파일 이름(각 발화의 ID)을 제외해야 합니다. 그렇지 않으면 이러한 ID가 말됩니다. 다음은 발화가 하나의 .txt 파일로 구성되는 방식의 예입니다.

```
This is the waistline, and it's falling.
We have trouble scoring.
It was Janet Maslin.
```

발화의 각 단락마다 별도의 오디오가 생성됩니다. 모든 문장을 하나의 오디오로 결합하려면 이를 한 단락으로 만듭니다.

>[!NOTE]
>- 테스트 스크립트는 1MB 미만의 txt 파일이어야 합니다. 지원되는 인코딩 형식으로는 ANSI/ASCII, UTF-8, UTF-8-BOM, UTF-16-LE 또는 UTF-16-BE가 있습니다.  
>- 생성된 오디오는 업로드된 테스트 스크립트와 기본 테스트 스크립트의 조합입니다.

5. 이 모델을 식별하는 데 도움이 되는 **이름** 및 **설명을** 입력합니다.

신중하게 이름을 선택합니다. 여기에 입력한 이름은 음성 합성 요청에서 음성을 지정할 때 SSML 입력의 일부로 사용됩니다. 문자, 숫자 및 몇 가지 문장 부호 문자(예: -, _ 및 (', '))만 허용됩니다. 신경망 음성 모델마다 다른 이름을 사용합니다.

**설명** 필드의 일반적인 용도는 모델을 만드는 데 사용된 데이터의 이름을 기록하는 것입니다.

6. 설정을 검토한 다음, **제출** 을 선택하여 모델 학습을 시작합니다.

> [!NOTE]
> 중복된 오디오 이름은 학습에서 제거됩니다. 선택한 데이터에 여러 .zip 파일에 동일한 오디오 이름이 포함되지 않도록 합니다.

**모델 학습** 테이블은 새로 만든 이 모델에 해당하는 새 항목을 표시합니다. 또한 테이블에는 처리 중, 성공, 실패 등의 상태가 표시됩니다.

테이블에 표시되는 상태는 다음과 같이 데이터를 음성 모델로 변환하는 프로세스를 반영합니다.

| 시스템 상태 | 의미 |
| ----- | ------- |
| 처리 중 | 음성 모델을 만들고 있습니다. |
| 성공 | 음성 모델을 만들었으며 배포할 수 있습니다. |
| 실패 | 보이지 않는 데이터 문제 또는 네트워크 문제와 같은 여러 가지 이유로 인해 음성 모델이 학습에 실패했습니다. |

학습 기간은 학습하는 데이터 양에 따라 달라집니다. 사용자 지정 신경망 음성을 학습하는 데 평균 40 컴퓨팅 시간이 소요됩니다. 

> [!NOTE]
> 표준 구독(S0) 사용자는 세 개의 음성을 동시에 학습시킬 수 있습니다. 한도에 도달하면 하나 이상의 음성 모델 학습이 완료될 때까지 기다린 후 다시 시도합니다. 

7. 모델 학습을 성공적으로 완료한 후에는 모델 세부 정보를 검토할 수 있습니다.

음성 모델이 성공적으로 빌드된 후에는 생성된 샘플 오디오 파일을 사용하여 테스트한 후 사용할 수 있도록 배포할 수 있습니다.

음성의 품질은 학습 데이터의 크기, 레코딩 품질, 대본 파일의 정확도, 학습 데이터의 녹음된 음성이 원하는 사용 사례에 맞게 디자인된 음색과 일치하는 정도 등 다양한 요인에 따라 달라집니다. [여기에서 당사 기술의 기능 및 한계 그리고 모델 품질 향상을 위한 모범 사례에 대해 자세히 알아보세요](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext). 

## <a name="create-and-use-a-custom-neural-voice-endpoint"></a>사용자 지정 신경망 음성 엔드포인트 만들기 및 사용

음성 모델을 성공적으로 만들고 테스트한 후에는 사용자 지정 Text to Speech 엔드포인트로 배포합니다. 그런 다음, REST API를 통해 Text to Speech 요청을 수행할 때 일반적인 엔드포인트 대신 이 엔드포인트를 사용합니다. 사용자 지정 엔드포인트는 모델을 배포하는 데 사용한 구독에서만 호출할 수 있습니다.

다음 작업을 수행하여 사용자 지정 신경망 음성 엔드포인트를 만들 수 있습니다.

1. **모델 배포** 탭에서 **모델 배포** 를 선택합니다. 
2. 다음으로, 사용자 지정 엔드포인트에 대한 **이름** 및 **설명** 을 입력합니다.
3. 그런 다음, 이 엔드포인트와 연결할 음성 모델을 선택합니다. 
4. 마지막으로 **배포** 를 선택하여 엔드포인트를 만듭니다.

**배포** 단추를 클릭하면 엔드포인트 테이블에 새 엔드포인트에 대한 항목이 표시됩니다. 새 엔드포인트를 인스턴스화하는 데 몇 분 정도 걸릴 수 있습니다. 배포 상태가 **성공** 이면 엔드포인트를 사용할 준비가 완료된 것입니다.

엔드포인트를 항상 사용하지 않는 경우 **일시 중단** 및 **계속** 할 수 있습니다. 일시 중단 후 엔드포인트가 다시 활성화되면 엔드포인트 URL은 동일하게 유지되므로 앱에서 코드를 변경할 필요가 없습니다. 

엔드포인트를 새 모델로 업데이트할 수도 있습니다. 모델을 변경하려면 새 모델의 이름을 업데이트하려는 것과 동일하게 지정해야 합니다. 

> [!NOTE]
>- 표준 구독(S0) 사용자는 각각 자체 사용자 지정 신경망 음성이 포함된 엔드포인트를 50개까지 만들 수 있습니다.
>- 사용자 지정 신경망 음성을 사용하려면 음성 모델 이름을 지정하고, HTTP 요청에서 직접 사용자 지정 URI를 사용하고, 동일한 구독을 사용하여 TTS 서비스의 인증을 통과해야 합니다.

엔드포인트가 배포된 후에는 엔드포인트 이름이 링크로 표시됩니다. 엔드포인트 키, 엔드포인트 URL 및 샘플 코드와 같이 엔드포인트 관련 정보를 표시하려면 링크를 클릭합니다.

사용자 지정 엔드포인트는 텍스트 음성 변환 요청에 사용되는 표준 엔드포인트와 기능적으로 동일합니다.  자세한 내용은 [Speech SDK](./get-started-text-to-speech.md) 또는 [REST API](rest-text-to-speech.md)를 참조하세요.

또한 친숙한 UI를 사용하여 오디오 출력을 세밀하게 조정할 수 있도록 하는 온라인 도구인 [오디오 콘텐츠 만들기](https://speech.microsoft.com/audiocontentcreation)도 사용할 수 있습니다.

## <a name="next-steps"></a>다음 단계

- [음성 샘플 녹음 방법](record-custom-voice-samples.md)
- [텍스트 음성 변환 API 참조](rest-text-to-speech.md)
- [긴 오디오 API](long-audio-api.md)
