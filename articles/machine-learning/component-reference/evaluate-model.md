---
title: '모델 평가: 구성 요소 참조'
titleSuffix: Azure Machine Learning
description: Azure Machine Learning 모델 평가 구성 요소를 사용하여 학습된 모델의 정확도를 측정하는 방법을 알아봅니다.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 07/27/2020
ms.openlocfilehash: ff2233f6a1b669856084cdd07591d99ee23dbe8c
ms.sourcegitcommit: 677e8acc9a2e8b842e4aef4472599f9264e989e7
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 11/11/2021
ms.locfileid: "132331227"
---
# <a name="evaluate-model-component"></a>모델 구성 요소 평가

이 문서에서는 Azure Machine Learning 디자이너의 구성 요소에 대해 설명합니다.

이 구성 요소를 사용하여 학습된 모델의 정확도를 측정합니다. 모델에서 생성된 점수를 포함하는 데이터 세트를 제공하고 모델 **평가** 구성 요소는 업계 표준 평가 메트릭 집합을 계산합니다.
  
 **모델 평가** 에서 반환되는 메트릭은 다음과 같이 평가하는 모델의 유형에 따라 달라집니다.  
  
-   **분류 모델**    
-   **회귀 모델**  
-   **클러스터링 모델**  


> [!TIP]
> 모델 평가를 처음 사용하는 경우 Stephen Elston 박사가 EdX의 [기계 학습 과정](/archive/blogs/machinelearning/new-edx-course-data-science-machine-learning-essentials)의 일부로 제공하는 비디오 시리즈를 참조하는 것이 좋습니다. 


## <a name="how-to-use-evaluate-model"></a>모델 평가 사용 방법
1. [점수 매기기 모델](./score-model.md)의 **점수가 매겨진 데이터 세트** 또는 [클러스터에 데이터 할당](./assign-data-to-clusters.md)의 결과 데이터 세트 출력을 **모델 평가** 의 왼쪽 입력 포트에 연결합니다. 
    > [!NOTE] 
    > "데이터 세트에서 열 선택"과 같은 구성 요소를 사용하여 입력 데이터 세트의 일부를 선택하는 경우 실제 레이블 열(학습에 사용), '점수가 매긴 확률' 열 및 '점수가 매긴 레이블' 열이 존재하여 AUC, 이진 분류/변칙 검색에 대한 정확도와 같은 메트릭을 계산해야 합니다.
    > 다중 클래스 분류/회귀의 메트릭을 계산하기 위해 실제 레이블 열인 '점수가 매겨진 레이블' 열이 존재합니다.
    > 클러스터링의 메트릭을 계산하기 위한 '할당' 열, 'DistancesToClusterCenter no.X' 열(X는 0부터 중심 수-1 사이의 중심 인덱스임)이 존재합니다.

    > [!IMPORTANT]
    > + 결과를 평가하려면 출력 데이터 세트에 모델 평가 구성 요소 요구 사항을 충족하는 특정 점수 열 이름이 포함되어야 합니다.
    > + `Labels` 열은 실제 레이블로 간주됩니다.
    > + 회귀 작업의 경우 평가할 데이터 세트에는 점수가 매겨진 레이블을 나타내는 `Regression Scored Labels`라는 하나의 열이 있어야 합니다.
    > + 이진 분류 작업의 경우 평가할 데이터 세트에는 각각 점수가 매겨진 레이블 및 확률을 나타내는 `Binary Class Scored Labels`, `Binary Class Scored Probabilities`라는 두 개의 열이 있어야 합니다.
    > + 다중 분류 작업의 경우 평가할 데이터 세트에는 점수가 매겨진 레이블을 나타내는 `Multi Class Scored Labels`라는 하나의 열이 있어야 합니다.
    > 업스트림 구성 요소의 출력에 이러한 열이 없는 경우 위의 요구 사항에 따라 수정해야 합니다.

2. [선택 사항] [점수 매기기 모델](./score-model.md)의 **점수가 매겨진 데이터 세트** 또는 두 번째 모델에 대한 클러스터에 데이터 할당의 결과 데이터 세트 출력을 **모델 평가** 의 **오른쪽** 입력 포트에 연결합니다. 동일한 데이터에서 서로 다른 두 모델의 결과를 쉽게 비교할 수 있습니다. 두 입력 알고리즘은 동일한 알고리즘 형식이어야 합니다. 또는 서로 다른 매개 변수를 사용하여 동일한 데이터에 대해 수행한 두 번의 실행 결과 생성된 점수를 비교할 수 있습니다.

    > [!NOTE]
    > 알고리즘 형식은 '기계 학습 알고리즘'의 '2클래스 분류', '다중 클래스 분류', '회귀', '클러스터링'을 나타냅니다. 

3. 파이프라인을 제출하여 평가 점수를 생성합니다.

## <a name="results"></a>결과

**모델 평가** 를 실행한 후 구성 요소를 선택하여 오른쪽에 있는 **모델 평가** 탐색 패널을 엽니다.  그런 다음, **출력 + 로그** 탭을 선택합니다. 그러면 해당 탭의 **데이터 출력** 섹션에 몇 개의 아이콘이 표시됩니다. **시각화** 아이콘에는 결과를 표시하는 첫 번째 방법인 막대 그래프 아이콘이 있습니다.

이진 분류의 경우 **시각화** 아이콘을 클릭한 후 이진 혼동 행렬을 시각화할 수 있습니다.
다중 분류의 경우 다음과 같이 **출력 + 로그** 탭에서 혼동 행렬 그림 파일을 찾을 수 있습니다.
> [!div class="mx-imgBorder"]
> ![업로드된 이미지 미리 보기](media/module/multi-class-confusion-matrix.png)

**모델 평가** 의 두 입력 모두에 데이터 세트를 연결하는 경우 결과에는 두 데이터 세트 또는 두 모델에 대한 메트릭이 포함됩니다.
왼쪽 포트에 연결된 모델이나 데이터가 보고서에 먼저 표시되고, 그 다음에 올바른 포트에 연결된 데이터 세트 또는 모델에 대한 메트릭이 표시됩니다.  

예를 들어, 다음 이미지는 동일한 데이터를 기준으로 작성되었지만 다른 매개 변수를 사용하는 두 클러스터링 모델의 결과를 비교해서 보여 줍니다.  

![Comparing2Models](media/module/evaluate-2-models.png)  

이것은 클러스터링 모델이므로 평가 결과는 두 회귀 모델의 점수를 비교하거나 두 분류 모델을 비교할 때와 다릅니다. 그러나 전체 프레젠테이션은 동일합니다. 

## <a name="metrics"></a>메트릭

이 섹션에서는 **모델 평가** 에서 사용하도록 지원되는 특정 유형의 모델에 대해 반환되는 메트릭을 설명합니다.

+ [분류 모델](#metrics-for-classification-models)
+ [회귀 모델](#metrics-for-regression-models)
+ [클러스터링 모델](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a>분류 모델에 대한 메트릭


이진 분류 모델을 평가할 때 다음과 같은 메트릭이 보고됩니다.
  
-   **정확도** 는 분류 모델의 적합성을 전체 사례에 대한 참 결과의 비율로 측정합니다.  
  
-   **정밀도** 는 모든 긍정 결과에 대한 참 결과의 비율입니다. 정밀도 = TP/(TP+FP)  
  
-   **재현율** 은 실제로 검색된 관련 인스턴스의 전체 크기에 대한 비율입니다. 재현율 = TP/(TP+FN)  
  
-   **F1 점수** 는 0~1 사이의 정밀도 및 재현율의 가중 평균으로 계산됩니다. 여기서 이상적인 F1 점수 값은 1입니다.  
  
-   **AUC** 는 y축의 참 긍정과 x축의 거짓 긍정을 사용하여 그린 곡선 아래의 영역을 측정합니다. 이 메트릭은 여러 가지 유형의 모델을 비교할 수 있는 단일 숫자를 제공하기 때문에 유용합니다. AUC는 classification-threshold-invariant입니다. 선택한 분류 임계값에 관계없이 모델 예측의 품질을 측정합니다.


### <a name="metrics-for-regression-models"></a>회귀 모델에 대한 메트릭
 
회귀 모델에 대해 반환되는 메트릭은 오류 크기를 예측하도록 디자인되었습니다.  관찰된 값과 예측 값 간의 차이가 적으면 모델은 데이터에 잘 맞는 것으로 간주됩니다. 그러나 오차(한 예측 지점과 해당 실제 값 간 차이) 패턴을 살펴보면 모델의 잠재적 편향에 대해 더 많은 정보를 얻을 수 있습니다.  
  
 회귀 모델 평가에 대해 다음과 같은 메트릭이 보고됩니다.
  
- **MAE(절대 평균 오차)** 는 예측값이 실제 결과와 얼마나 가까운지를 측정합니다. 따라서 점수가 낮을수록 좋습니다.  
  
- **RMSE(제곱 평균 오차)** 는 모델의 오류를 요약하는 단일 값을 만듭니다. 이 메트릭은 차이를 제곱하여 과다 예측과 미달 예측 간 차이를 무시합니다.  
  
- **RAE(상대 절대 오차)** 는 예상 값과 실제 값의 상대 절대 차이입니다. 평균 차이를 산술 평균으로 나누기 때문에 상대 값이 됩니다.  
  
- **RSE(상대 제곱 오차)** 는 유사하게 실제 값의 총 제곱 오차를 나누어 예측 값의 총 제곱 오차를 정규화합니다.  
  

  
- R <sup>2</sup>라고도 하는 **결정 계수** 는 모델의 예측 기능을 0에서 1 사이의 값으로 나타냅니다. 0은 모델이 무작위로 사용됨을 의미하고(아무 것도 설명하지 않음), 1은 완벽하게 잘 맞음을 의미합니다. 그러나 낮은 값은 완전히 정상이고 높은 값은 주의 대상이 될 수 있으므로 R<sup>2</sup> 값을 해석할 때는 주의해야 합니다.

###  <a name="metrics-for-clustering-models"></a>클러스터링 모델에 대한 메트릭

클러스터링 모델은 다양한 측면에서 분류 및 회귀 모델과 크게 다르므로 [모델 평가](evaluate-model.md)에서도 클러스터링 모델에 대해서는 다른 통계 세트를 반환합니다.  
  
 클러스터링 모델에 대해 반환되는 통계는 각 클러스터에 할당된 데이터 요소 수, 클러스터 간의 구분 간격 및 각 클러스터 내에서 데이터 요소가 얼마나 촘촘히 붙어 있는지를 나타냅니다.  
  
 클러스터당 통계를 포함하는 추가 행을 비롯한 전체 데이터 세트에 대해 클러스터링 모델 통계의 평균을 계산합니다.  
  
클러스터링 모델 평가에 대해 다음과 같은 메트릭이 보고됩니다.
    
-   **다른 중심까지의 평균 거리** 열의 점수는 클러스터의 각 요소가 다른 모든 클러스터의 중심과 평균적으로 얼마나 가까운지를 나타냅니다.   

-   **클러스터 중심까지의 평균 거리** 열의 점수는 클러스터의 모든 요소와 해당 클러스터의 중심이 얼마나 가까운지를 나타냅니다.  
  
-   **요소 수** 열에는 각 클러스터에 할당된 데이터 요소의 수와 클러스터에 있는 총 데이터 요소 수가 표시됩니다.  
  
     클러스터에 할당된 데이터 요소 수가 사용 가능한 총 데이터 요소 수보다 적으면 데이터 요소를 클러스터에 할당할 수 없음을 의미합니다.  
  
-   **클러스터 센터까지의 최대 거리** 인 열의 점수는 각 요소와 해당 요소의 클러스터 중심 사이의 최대 거리를 나타냅니다.  
  
     이 수치가 높으면 클러스터가 널리 분산된 것을 의미할 수 있습니다. 클러스터의 분산을 확인하려면 **클러스터 센터까지의 평균 거리** 와 이 통계를 함께 검토해야 합니다.   

-   결과의 각 섹션 아래쪽에 있는 **결합된 평가** 점수에는 해당 특정 모델에서 만든 클러스터의 평균 점수가 나열됩니다.  

## <a name="next-steps"></a>다음 단계

Azure Machine Learning [사용할 수 있는 구성 요소 집합을](component-reference.md) 참조하세요.
